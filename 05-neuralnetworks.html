<!DOCTYPE html>
<html lang="en"><head>
<script src="05-neuralnetworks_files/libs/quarto-html/tabby.min.js"></script>
<script src="05-neuralnetworks_files/libs/quarto-html/popper.min.js"></script>
<script src="05-neuralnetworks_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="05-neuralnetworks_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="05-neuralnetworks_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="05-neuralnetworks_files/libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="05-neuralnetworks_files/libs/quarto-contrib/videojs/video.min.js"></script>
<link href="05-neuralnetworks_files/libs/quarto-contrib/videojs/video-js.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Matteo Francia   DISI — University of Bologna   m.francia@unibo.it">
  <title>Machine Learning and Data Mining (Module 2)</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="05-neuralnetworks_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="05-neuralnetworks_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="05-neuralnetworks_files/libs/revealjs/dist/theme/quarto-6391498a111a1f00b0d941bda0c7e264.css">
  <link href="05-neuralnetworks_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="05-neuralnetworks_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="05-neuralnetworks_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="05-neuralnetworks_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Machine Learning and Data Mining (Module 2)</h1>
  <p class="subtitle">Modeling: Neural Networks</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Matteo Francia <br> DISI — University of Bologna <br> m.francia@unibo.it 
</div>
</div>
</div>

</section>
<section id="section" class="title-slide slide level1 center">
<h1></h1>

<img src="./img/crispdm_me.svg" class="center-img r-stretch"></section>

<section id="recalling-the-machine-learning-pipeline" class="title-slide slide level1 center">
<h1>Recalling the Machine Learning pipeline</h1>
<p>We now focus on the model, the “heart” of the AI in our system</p>

<img data-src="./img/datapreprocessing/pipeline.svg" class="r-stretch quarto-figure-center"><p class="caption">Data pipeline</p><ul>
<li>With <em>model</em>, we refer to the “mechanism” with which input data are transformed into outputs</li>
<li>A ML algorithm <em>trains</em> a ML model
<ul>
<li>Usually, this “mechanism” is based on math, geometry, statistics, etc.</li>
</ul></li>
<li>Even with the best model available, if I use “dirty” or “insignificant” input data, the system will perform poorly</li>
</ul>
</section>

<section id="neural-networks" class="title-slide slide level1 center">
<h1>Neural Networks</h1>
<p><em>Neural Networks</em> (NN): the key idea is to imitate, as far as possible, the neurons of the human brain</p>
<ul>
<li><em>Networks</em> since neurons are connected through each other</li>
<li>Several scientific studies reported the structure of the biological neuron:</li>
</ul>

<img data-src="./img/neuralnetworks/3%20Model52.png" class="r-stretch quarto-figure-center"><p class="caption">Biological neuron</p><ul>
<li>The <em>axon</em> carries nerve signals away from the soma (from left to right)</li>
<li>The <em>cell body</em> is where signals are aggregated and processed</li>
<li>The <em>dendrites</em> is where the majority of input to the neuron occurs from other cells</li>
</ul>
</section>

<section id="artificial-neuron-perceptron" class="title-slide slide level1 center">
<h1>Artificial Neuron (perceptron)</h1>
<div class="columns">
<div class="column" style="width:50%;">
<p>The first scheme about the neuron has been introduced by <span class="citation" data-cites="mcculloch1943logical">(<a href="#/references" role="doc-biblioref" onclick="">McCulloch and Pitts 1943</a>)</span></p>
<p>The first Artificial Neuron (AN) has been introduced by <em>Rosenblatt</em> in 1957</p>
<ul>
<li><em>Inputs</em> are digital numbers (not analog signals)</li>
<li>Inputs are <em>weighted</em> (signals are not all equally important)</li>
<li>Inputs are <em>merged</em> with a sum function (plus a <em>bias</em>)</li>
<li>An <em>activation function</em> is used to generate the final output:
<ul>
<li>Also the human brain <em>filters inputs</em>, it is impossible to always take everything into account</li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model53.png"></p>
<figcaption>Artificial neuron</figcaption>
</figure>
</div>
</div></div>
</section>

<section id="an-example-of-a-working-an" class="title-slide slide level1 center">
<h1>An example of a working AN</h1>
<p>Will I pass the Machine Learning exam?</p>

<img data-src="./img/neuralnetworks/slide54.png" class="r-stretch quarto-figure-center"><p class="caption">Example of neuron</p><p><span class="math inline">\(y' = \begin{cases}1, ~if~ 0.3\cdot x_1 + 0.8 \cdot x_2 + 0.5 \cdot x_3 \ge 3\\0, otherwise\end{cases}\)</span></p>
</section>

<section id="examples-of-working-ans-boolean-functions" class="title-slide slide level1 center">
<h1>Examples of working ANs: Boolean functions</h1>
<p>How can we implement the following operators?</p>
<div class="columns">
<div class="column" style="width:33%;">
<p><strong>not</strong></p>
<table>
<tbody><tr>
<td>
<span class="math inline">\(x_1\)</span>
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<td>
</td>
<td>
<strong>1</strong>
</td>
<td>
<em>0</em>
</td>
</tr>
</tbody></table>
</div><div class="column" style="width:33%;">
<p><strong>and</strong></p>
<table>
<tbody><tr>
<td>
<span class="math inline">\(x_1\)</span> / <span class="math inline">\(x_2\)</span>
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<td>
0
</td>
<td>
<em>0</em>
</td>
<td>
<em>0</em>
</td>
</tr>
<tr>
<td>
1
</td>
<td>
<em>0</em>
</td>
<td>
<strong>1</strong>
</td>
</tr>
</tbody></table>
</div><div class="column" style="width:33%;">
<p><strong>or</strong></p>
<table>
<tbody><tr>
<td>
<span class="math inline">\(x_1\)</span> / <span class="math inline">\(x_2\)</span>
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<td>
0
</td>
<td>
<em>0</em>
</td>
<td>
<strong>1</strong>
</td>
</tr>
<tr>
<td>
1
</td>
<td>
<strong>1</strong>
</td>
<td>
<strong>1</strong>
</td>
</tr>
</tbody></table>
</div></div>
</section>

<section id="examples-of-working-ans-boolean-functions-1" class="title-slide slide level1 center">
<h1>Examples of working ANs: Boolean functions</h1>

<img data-src="./img/neuralnetworks/43%20-%20AI%20ANN2.png" class="r-stretch quarto-figure-center"><p class="caption">Boolean functions</p></section>

<section id="examples-of-working-ans-boolean-functions-2" class="title-slide slide level1 center">
<h1>Examples of working ANs: Boolean functions</h1>
<p>What about <strong>xor</strong>?</p>
<table>
<tbody><tr>
<td>
<span class="math inline">\(x_1\)</span> / <span class="math inline">\(x_2\)</span>
</td>
<td>
0
</td>
<td>
1
</td>
</tr>
<tr>
<td>
0
</td>
<td>
<em>0</em>
</td>
<td>
<strong>1</strong>
</td>
</tr>
<tr>
<td>
1
</td>
<td>
<strong>1</strong>
</td>
<td>
<em>0</em>
</td>
</tr>
</tbody></table>
</section>

<section id="linear-vs-non-linear-problems" class="title-slide slide level1 center">
<h1>Linear vs Non-linear problems</h1>
<p>A single AN <em>can solve only linear problems</em>!</p>

<img data-src="./img/neuralnetworks/3%20Model56.png" class="r-stretch quarto-figure-center"><p class="caption">Linear vs Non-linear</p><p>The solution is to use more ANs organized on different layers → <strong>Multi-Layer Perceptron (MLP)</strong></p>
<ul>
<li>It is not so easy, since this introduces several mathematical problems</li>
<li>Besides, we greatly improve the computational load</li>
</ul>
</section>

<section id="artificial-neural-networks-ann" class="title-slide slide level1 center">
<h1>Artificial Neural Networks (ANN)</h1>
<div class="columns">
<div class="column" style="width:65%;">
<p><strong>Neural Networks</strong> are groups of artificial neurons are organized in different layers</p>
<ul>
<li>An <em>input layer</em> (input of the network)</li>
<li>An <em>output layer</em> (output of the network)</li>
<li>One or more <em>hidden layer(s)</em></li>
</ul>
<p>Each neuron is fully connected with those of the next level.</p>
<ul>
<li>Again, we try to imitate the hierarchical nature of our neurons</li>
<li>We have “only” about ten levels between the retina and the actuator muscles.</li>
<li>… otherwise, we would be too slow to react to stimuli.</li>
</ul>
</div><div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/56a.png"></p>
<figcaption>Multiple layers</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/56b.png"></p>
<figcaption>Biological layers</figcaption>
</figure>
</div>
</div></div>
</section>

<section id="ann-typologies" class="title-slide slide level1 center">
<h1>ANN typologies</h1>
<div class="columns">
<div class="column" style="width:70%;">
<p><strong>Feed forward</strong>:</p>
<ul>
<li>The connections connect the neurons of one level with the neurons of the next level</li>
<li>Backward connections or connections to the same level are not allowed</li>
</ul>
<p><strong>Recurrent</strong>:</p>
<ul>
<li>Feedback connections are expected
<ul>
<li>Generally towards neurons of the same level, but also backward</li>
</ul></li>
<li>Suitable for sequences because they have a (short-term) memory effect</li>
</ul>
<p>In our course, we will use only FF NN!</p>
</div><div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model59.png"></p>
<figcaption>Feed forward</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model60.png"></p>
<figcaption>Recurrent</figcaption>
</figure>
</div>
</div></div>
</section>

<section id="activation-functions" class="title-slide slide level1 center">
<h1>Activation functions</h1>
<p><strong>Activation functions</strong> define the output of the neuron given an input or set of inputs:</p>
<ul>
<li>They output a small value for small inputs, and a larger value if its inputs exceed a threshold</li>
<li>They are a sort of switches of the artificial neuron</li>
</ul>

<img data-src="./img/neuralnetworks/3%20Model55.png" class="r-stretch quarto-figure-center"><p class="caption"><a href="https://medium.com/@shrutijadon/survey-on-activation-functions-for-deep-learning-9689331ba092">Activation Functions</a></p></section>

<section id="activation-functions-1" class="title-slide slide level1 center">
<h1>Activation functions</h1>
<div class="columns">
<div class="column" style="width:33%;">
<p><strong>Relu</strong></p>
<video id="video_shortcode_videojs_video1" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="vid/relu.mp4"></video>
</div><div class="column" style="width:33%;">
<p><strong>Sigmoid</strong></p>
<video id="video_shortcode_videojs_video2" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="vid/sigmoid.mp4"></video>
</div><div class="column" style="width:33%;">
<p><strong>Linear</strong></p>
<video id="video_shortcode_videojs_video3" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="vid/linear.mp4"></video>
</div></div>
</section>

<section id="universal-approximation-theorem" class="title-slide slide level1 center">
<h1>Universal Approximation Theorem</h1>
<p><strong>Universal Approximation Theorem</strong>: a NN with <em>at least 1 hidden layer</em> can approximate any continuous function <em>to any desired degree of accuracy</em>, given <em>sufficient neurons</em> in that hidden layer, the <em>right weights and biases</em>, and a <em>non-polynomial activation</em> function.</p>

<img data-src="img/neuralnetworks/universaltheorem1.svg" class="r-stretch quarto-figure-center"><p class="caption">Universal Approximation Theorem</p><p>Limitations</p>
<ul>
<li>The theorem applies to feedforward neural networks with <span class="math inline">\(n\)</span> inputs, a single hidden layer (“shallow” and wide), and 1 output</li>
<li>Achieving a close approximation might require an impractically large number of neurons, making the network hard to train</li>
<li>The theorem assumes that the “right” weights and biases exist but does not address how to find them</li>
<li>Not applicable to discontinuous functions</li>
</ul>
</section>

<section id="håstads-switching-lemma-hastad1986almost" class="title-slide slide level1 center">
<h1>Håstad’s switching lemma <span class="citation" data-cites="hastad1986almost">(<a href="#/references" role="doc-biblioref" onclick="">Hastad 1986</a>)</span></h1>
<p><strong>Håstad’s switching lemma</strong>: certain functions, while easily represented by deep networks with a modest number of neurons, require an exponentially larger number of neurons to represent accurately if constrained to a single hidden layer.</p>
<p>“Global” functions are harder to be approximated, for instance</p>
<ul>
<li>The <em>parity function</em> determines whether the number of 1s in a binary input string is odd or even.</li>
<li>The <em>majority function</em> outputs 1 if more than half of the input bits are 1, and 0 otherwise.</li>
</ul>
<p>This lemma provides a theoretical foundation for using depth in both circuit complexity and neural networks</p>
<ul>
<li>It justifies the need for layered structure when working with complex, globally-dependent functions.</li>
</ul>
</section>

<section id="universal-approximation-theorem-kidger2020universal" class="title-slide slide level1 center">
<h1>Universal Approximation Theorem <span class="citation" data-cites="kidger2020universal">(<a href="#/references" role="doc-biblioref" onclick="">Kidger and Lyons 2020</a>)</span></h1>
<p><span class="citation" data-cites="kidger2020universal">(<a href="#/references" role="doc-biblioref" onclick="">Kidger and Lyons 2020</a>)</span>: let <span class="math inline">\(n\)</span> be the number of inputs neurons, <span class="math inline">\(m\)</span> be the number of output neurons, and let <span class="math inline">\(\rho\)</span> be any nonaffine continuous function, with a continuous nonzero derivative at some point. The class of neural networks of arbitrary depth, width <span class="math inline">\(n + m + 2\)</span> and activation function <span class="math inline">\(\rho\)</span>, is dense in <span class="math inline">\(C(K; R^m)\)</span> for <span class="math inline">\(K \subseteq R^n\)</span> with <span class="math inline">\(K\)</span> compact. This covers any activation function, including polynomial activation functions.</p>

<img data-src="img/neuralnetworks/universaltheorem2.svg" class="r-stretch quarto-figure-center"><p class="caption">Universal Approximation Theorem for Deep Narrow Networks</p><p>This is why deep neural networks work</p>
</section>

<section id="neural-networks-training-intuition" class="title-slide slide level1 center">
<h1>Neural networks training: intuition</h1>

<img data-src="./img/neuralnetworks/3%20Model65.png" class="r-stretch quarto-figure-center"><p class="caption">Training</p></section>

<section id="neural-networks-training" class="title-slide slide level1 center">
<h1>Neural networks training</h1>
<div class="columns">
<div class="column" style="width:70%;">
<p>General considerations about Neural Network architectures</p>
<ul>
<li><em>Greater number of hidden layers (therefore neurons)</em>
<ul>
<li>→ <em>better performance</em></li>
<li>→ <em>need for more training data</em></li>
<li>→ <em>greater computational load</em></li>
</ul></li>
</ul>
<p>How is it possible to train a neural network?</p>
<ul>
<li>Training a neural network is complicated, but we can use specific frameworks</li>
<li>The same happens in Machine Learning and the <em>scikit-Learn</em> library</li>
</ul>
</div><div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model61.png"></p>
<figcaption>TensorFlow</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model62.png"></p>
<figcaption>Pytorch</figcaption>
</figure>
</div>
</div></div>
</section>

<section id="deep-neural-networds-dnn" class="title-slide slide level1 center">
<h1>Deep Neural Networds (DNN)</h1>
<p><strong>Deep Learning</strong>: a branch of ML that avoids the problematic phase of feature extraction (also) with high-dimensional inputs.</p>
<div class="columns">
<div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/ai-ml-dl.png"></p>
<figcaption>Deep Learning</figcaption>
</figure>
</div>
</div><div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model51.jpg"></p>
<figcaption>Deep Learning</figcaption>
</figure>
</div>
</div></div>
<p>Feature extraction requires human intervention.</p>
<ul>
<li>… Often, this is the weak link in the chain!</li>
</ul>
</section>

<section id="ann-and-dnn-training" class="title-slide slide level1 center">
<h1>ANN and DNN training</h1>
<p>Training a NN means tune the weights to optimize the prediction accuracy</p>
<ul>
<li>… by <em>minimizing</em> a loss/cost function.</li>
</ul>
<video id="video_shortcode_videojs_video4" class="video-js vjs-default-skin vjs-fluid" controls="" preload="auto" data-setup="{}" title=""><source src="vid/sigmoid-big.mp4"></video>
</section>

<section id="ann-and-dnn-training-a-visual-guide" class="title-slide slide level1 center">
<h1>ANN and DNN training: a visual guide</h1>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model75.gif"></p>
<figcaption>Gradient descent</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<ol type="1">
<li>This surface is the solution space of the <em>loss function</em>
<ul>
<li>low values → low error</li>
</ul></li>
<li><em>Starting point</em>
<ul>
<li>Output of the NN with initial (random) weights</li>
</ul></li>
<li><em>Global minimum</em>: the desired goal point!</li>
<li>The learning procedure is performed in an <em>iterative manner</em>
<ul>
<li>Following the gradient, the optimizers look for the (global) minimum</li>
</ul></li>
<li>Each step is proportional to the <em>learning rate</em> adopted</li>
<li><em>Local minimum</em>
<ul>
<li>The loss function of DL models usually has many local minima.</li>
<li>The solution obtained by the final iteration may only locally minimize the loss function.</li>
</ul></li>
</ol>
</div></div>
</section>

<section id="ann-and-dnn-training-1" class="title-slide slide level1 center">
<h1>ANN and DNN training</h1>
<p>The <em>cost function</em> is a mathematical formulation of the learning goal</p>
<ul>
<li>Measures the error between the prediction and the ground truth (label)</li>
<li>Presents the performance (or error) in the form of a single real number</li>
</ul>
<p><strong>Cross Entropy</strong> is the distance between what the model believes the output distribution should be &amp; what the original distribution is</p>
<ul>
<li>In order to use the <em>Cross Entropy</em> loss, the output layer must output probabilities.</li>
<li><em>Binary Cross Entropy (BCE)</em>
<ul>
<li><span class="math inline">\(Loss = -y_i \cdot log (\hat{y}_i) - (1 - y_i) \cdot log(1 - \hat{y}_i)\)</span>
<ul>
<li><span class="math inline">\(\hat{y}_i\)</span> is the i-th scalar value in the model output (prediction), <span class="math inline">\(y_i\)</span> is the corresponding target (label) value
<ul>
<li><span class="math inline">\(-y_i \cdot log (\hat{y}_i)\)</span> cancels out if the target is 0</li>
<li><span class="math inline">\((1 - y_i) \cdot log(1 - \hat{y}_i)\)</span> cancels out if the target is 1</li>
</ul></li>
</ul></li>
</ul></li>
<li><em>Categorical Cross Entropy (CCE)</em>
<ul>
<li><span class="math inline">\(Loss = -\sum_i y_i \cdot log(\hat{y}_i)\)</span></li>
</ul></li>
</ul>
</section>

<section id="softmax" class="title-slide slide level1 center">
<h1>Softmax</h1>
<p>The <em>softmax</em> layer transforms an n-dimensional vector of real numbers into a vector of real numbers <span class="math inline">\(\in [0, 1]\)</span> which adds up to 1</p>
<ul>
<li>The Softmax activation function determines the final probability value of each class <span class="math inline">\(p_i = \frac{e^{a_k}}{\sum_{k=1}^n e^{a_k}}\)</span></li>
<li>Softmax is a continuously differentiable function.</li>
</ul>

<img data-src="./img/neuralnetworks/3%20Model66.png" class="r-stretch quarto-figure-center"><p class="caption">Softmax</p><p>See also:</p>
<ul>
<li><a href="https://peterroelants.github.io/posts/cross-entropy-softmax/">Cross entropy softmax</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2021/04/introduction-to-softmax-for-neural-network/">Introduction to softmax for neural network</a></li>
</ul>
</section>

<section id="cross-entropy-softmax" class="title-slide slide level1 center">
<h1>Cross Entropy + Softmax</h1>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model67.jpg"></p>
<figcaption>Image classification</figcaption>
</figure>
</div>
<div class="columns">
<div class="column" style="width:33%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model68.png"></p>
<figcaption>CCE</figcaption>
</figure>
</div>
<p><span class="math inline">\(CCE = -log_2 0.755 = 0.3677\)</span></p>
</div><div class="column" style="width:33%;">
<p>After some training iterations…</p>
</div><div class="column" style="width:33%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model69.jpg"></p>
<figcaption>CCE</figcaption>
</figure>
</div>
<p><span class="math inline">\(CCE = -log_2 0.0938 = 0.0923\)</span></p>
<p><em>The loss function has decreased!</em></p>
</div></div>
<p>See <a href="https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e">Cross entropy loss function</a></p>
</section>

<section id="ann-and-dnn-training-2" class="title-slide slide level1 center">
<h1>ANN and DNN training</h1>
<p>How to minimize the loss?</p>
<ul>
<li><em>Adjusting (changing) the weights and the bias of every neuron</em></li>
</ul>

<img data-src="./img/neuralnetworks/3%20Model53.png" class="r-stretch quarto-figure-center"><p class="caption">Choosing the learning rate</p></section>

<section id="gradient-descent" class="title-slide slide level1 center">
<h1>Gradient descent</h1>
<p><strong>Gradient descent</strong> is a method for unconstrained mathematical optimization.</p>
<ul>
<li>It is a first-order iterative algorithm for minimizing a differentiable multivariate function <span class="math inline">\(F(\mathbf {x} )\)</span>.</li>
<li>Take repeated steps in the opposite direction of the gradient of <span class="math inline">\(F(\mathbf {x})\)</span> at the current point: the direction of steepest descent.</li>
<li>Conversely, stepping in the direction of the gradient will lead to a trajectory that maximizes that function (gradient ascent)</li>
</ul>
<div class="columns">
<div class="column" style="width:75%;">
<p>If <span class="math inline">\(F(\mathbf {x})\)</span> is defined and differentiable in a neighborhood of a point <span class="math inline">\(\mathbf {a}\)</span>, then</p>
<p><span class="math inline">\(F(\mathbf {x} )\)</span> decreases fastest in the direction of the negative gradient of <span class="math inline">\(F\)</span> at <span class="math inline">\(\mathbf {a}\)</span>, that is <span class="math inline">\(-\nabla F(\mathbf {a} )\)</span>.</p>
<p>It follows that, if <span class="math inline">\(\mathbf {a} _{n+1}=\mathbf {a} _{n}-\eta \nabla F(\mathbf {a} _{n})\)</span></p>
<p>For a small enough step size or learning rate <span class="math inline">\(\eta \in \mathbb {R} _{+}\)</span>, then <span class="math inline">\(F(\mathbf {a_{n}} ) \geq F(\mathbf {a_{n+1}})\)</span></p>
</div><div class="column" style="width:25%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Gradient_descent.svg/350px-Gradient_descent.svg.png"></p>
<figcaption>Gradient Descent</figcaption>
</figure>
</div>
</div></div>
</section>

<section id="gradient-descent-1" class="title-slide slide level1 center">
<h1>Gradient descent</h1>
<div class="columns">
<div class="column" style="width:60%;">
<p><strong>Vanilla Gradient Descent</strong></p>
<ol type="1">
<li>Start with random initial values for parameters (weights and biases)</li>
<li>Use the current parameters to compute predictions on the training data</li>
<li>Compute the cost function</li>
<li>Calculate the gradient of the cost function with respect to each parameter <span class="math inline">\(\nabla J(\Theta)\)</span></li>
<li>Adjust each parameter in the opposite direction of the gradient. <span class="math inline">\(\Theta = \Theta−\eta \cdot \nabla J(\Theta)\)</span></li>
<li>Repeat steps 2–5 for each <em>epoch (i.e., iteration over the entire dataset)</em> until the cost function converges to a minimum or reaches a predefined number of epochs</li>
</ol>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model71.png"></p>
<figcaption>Vanilla Gradient Descent</figcaption>
</figure>
</div>
</div></div>
<p>Vanilla Gradient Descent</p>
<ul>
<li>Smooth convergence</li>
<li>Not recommended for huge training dataset → Slow and computationally expensive algorithm</li>
</ul>
</section>

<section id="gradient-descent-2" class="title-slide slide level1 center">
<h1>Gradient descent</h1>
<div class="columns">
<div class="column" style="width:70%;">
<p><strong>(Mini-batch) Stochastic Gradient Descent (SGD)</strong></p>
<ol type="1">
<li>Start with random values for parameters (e.g., weights and biases)</li>
<li>Split the dataset into multiple small batches of a predefined size</li>
<li>For each mini-batch <span class="math inline">\(\mathbf{B}\)</span>:
<ol type="1">
<li>Make predictions using the current parameters for each sample in <span class="math inline">\(\mathbf{B}\)</span></li>
<li>Calculate the cost or error for the mini-batch</li>
<li>Compute the gradient of the cost function with respect to each parameter</li>
<li>Adjust each parameter. <span class="math inline">\(\Theta = \Theta−\eta \cdot \nabla J(\Theta; \mathbf{B})\)</span></li>
</ol></li>
<li>Go through all mini-batches until every sample in the dataset has been used once (one epoch), then shuffle the dataset and repeat the above process for the next epoch.</li>
</ol>
</div><div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model72.jpg"></p>
<figcaption>Stochastic Gradient Descent</figcaption>
</figure>
</div>
</div></div>
<p>Advantages</p>
<ul>
<li><em>Faster Training</em>: more frequent parameter updates than batch gradient descent, leading to faster convergence.</li>
<li><em>Efficient GPU/CPU Utilization</em>: Mini-batch enable parallel processing and faster computation on GPUs.</li>
</ul>
<p>Drawbacks</p>
<ul>
<li><em>Selecting an optimal batch size requires some experimentation</em>, as it can affect both the speed and stability of convergence.</li>
<li>Mini-batch gradient descent is <em>less stable than full-batch gradient descent</em>, especially for small batch sizes.</li>
</ul>
</section>

<section id="gradient-descent-3" class="title-slide slide level1 center">
<h1>Gradient descent</h1>
<p><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Extensions_and_variants">Many algorithms exist</a>, such as <strong>Adam</strong> (Adaptive Moment Estimation)</p>
<ul>
<li>A <em>stochastic gradient descent</em> method</li>
<li>Fewer parameters than SGD</li>
</ul>
<p>Adam is based on two principles:</p>
<ul>
<li><strong>Momentum</strong>
<ul>
<li>Exponentially decaying average of past gradients to “smooth out” the gradients over multiple steps</li>
<li>This helps the optimizer move faster in the direction of the overall gradient, improving convergence speed</li>
</ul></li>
<li><strong>Adaptive Learning Rates</strong>
<ul>
<li>A moving average tracks the squared gradients, adjusting the learning rate based on the variability of the gradient</li>
<li>Parameters with large (small) gradient changes get smaller (larger) learning rates</li>
</ul></li>
</ul>
</section>

<section id="terminology" class="title-slide slide level1 center">
<h1><a href="https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/">Terminology</a></h1>
<p><strong>Batch (size)</strong>: the hyperparameter of gradient descent that controls the number of training samples to work through before the model’s internal parameters are updated.</p>
<ul>
<li>Typically batch size is a multiple of the power of two (16, 32, 64,…)</li>
<li>Too small batch size can compromise the stability of the learning phase</li>
<li>The larger the batch size, the more video memory is used! (check your GPU specs)</li>
<li>Empirically, the batch size may be (at least) equal to the number of classes</li>
</ul>
<p><strong>#Iterations</strong>: the size of the training set / the batch size</p>
<p><strong>Epoch</strong>: the learning procedure is applied to the entire training dataset:</p>
<ul>
<li>One epoch means that each sample in the training has had an opportunity to update the weights</li>
<li>An epoch is comprised of one or more batches (or iterations).</li>
<li>The number of epochs is traditionally large (10, 100, 1000, …)</li>
</ul>
</section>

<section id="delta-rule" class="title-slide slide level1 center">
<h1>Delta rule</h1>
<p>We can apply the <em>Widrow-Hoff (delta) Rule</em> on the <em>perceptron</em> (simple gradient descent technique)</p>
<p>For a neuron <span class="math inline">\(j\)</span> with activation function <span class="math inline">\(g(x)\)</span>, the delta rule for neuron <span class="math inline">\(j\)</span>’s <span class="math inline">\(i\)</span>-th weight <span class="math inline">\(w_{ji}\)</span> is given by</p>
<p><span class="math inline">\(\Delta w_{ij} = \eta (y_i - \hat{y}_i)g'(h_j)x_i\)</span></p>
<ul>
<li><span class="math inline">\(x_i\)</span> is the <span class="math inline">\(i\)</span>-th input</li>
<li><span class="math inline">\(h\)</span> is the weighted sum of inputs <span class="math inline">\(h_{j}=\sum _{i}x_{i}w_{ji}\)</span></li>
<li><span class="math inline">\(g'()\)</span> is the derivative of the activation function</li>
<li><span class="math inline">\(\hat{y}_i\)</span> is the actual output, <span class="math inline">\(y_i\)</span> is the target output</li>
<li><span class="math inline">\(\eta\)</span> is the learning rate</li>
</ul>
</section>

<section id="backpropagation" class="title-slide slide level1 center">
<h1>Backpropagation</h1>
<p><strong>Backpropagation</strong> (i.e., <em>backward propagation of errors</em>) propagates the error to the input of a ANN</p>
<ul>
<li>We cannot directly compute the derivative of the loss function with respect to the outputs of the network</li>
<li>Backpropagation is a local process: neurons are completely unaware of the complete topology of the network</li>
<li>Apply the <em>chain rule</em> to propagate the derivative of the loss function up to the inputs of the network</li>
</ul>

<img data-src="./img/neuralnetworks/3%20Model74.png" class="r-stretch quarto-figure-center"><p class="caption">Chain rule</p><ul>
<li>The introduction of backpropagation has been fundamental in order to train DNNs!</li>
<li>Delta rule is a special case of the more general backpropagation algorithm</li>
</ul>
</section>

<section id="backpropagation-1" class="title-slide slide level1 center">
<h1>Backpropagation</h1>
<p>Steps</p>
<ol type="1">
<li><em>Forward Pass</em>: the network takes input data, computes outputs layer by layer, and calculates a final prediction.
<ul>
<li><span class="math inline">\(\hat{y}=f^{L}(W^{L}f^{L-1}(W^{L-1}\cdots f^{1}(W^{1}x)\cdots))\)</span></li>
</ul></li>
<li><em>Loss Calculation</em>: the loss function quantifies the difference between the predicted output and the true output.
<ul>
<li>Given an input–output pair (x, y), it is <span class="math inline">\(C(y_i, \hat{y_i}) = C(y,f^{L}(W^{L}f^{L-1}(W^{L-1}\cdots f^{2}(W^{2}f^{1}(W^{1}x))\cdots )))\)</span></li>
</ul></li>
<li><em>Backward Pass</em>: gradients are computed by propagating the error backward to each layer in the network, using the <em>chain rule</em></li>
<li><em>Parameter Update</em>: using gradient descent, each parameter (weight and bias) is updated to reduce the error.</li>
</ol>
<p>The <strong>chain rule</strong> is used to differentiate composite functions.</p>
<ul>
<li>Given two functions <span class="math inline">\(f()\)</span> and <span class="math inline">\(g()\)</span> and <span class="math inline">\(y=f(g(x))\)</span>, the chain rule states that <span class="math inline">\(\frac{\delta y}{\delta x} = \frac{\delta y}{\delta g} \cdot \frac{\delta g}{\delta x}\)</span></li>
</ul>
<p>For instance, given <span class="math inline">\(y = sin(x^2)\)</span>, it is:</p>
<ul>
<li><span class="math inline">\(\frac{\delta y}{\delta g} = cos(g)\)</span>; <span class="math inline">\(\frac{\delta g}{\delta x} = 2x\)</span>; finally, <span class="math inline">\(\frac{\delta y}{\delta x} = cos(x^2) \cdot 2x\)</span></li>
</ul>
</section>

<section id="backpropagation-2" class="title-slide slide level1 center">
<h1>Backpropagation</h1>
<p>The problem with DNNs is that we have hidden layers, the loss functions depend on “hidden parameters” <span class="math inline">\(𝑤\)</span></p>

<img data-src="./img/neuralnetworks/3%20Model73.png" class="r-stretch quarto-figure-center"><p class="caption">Chain rule</p><p><span class="math inline">\(C(y,f^{L}(W^{L}f^{L-1}(W^{L-1}\cdots f^{2}(W^{2}f^{1}(W^{1}x))\cdots )))\)</span></p>
<ul>
<li><span class="math inline">\(x\)</span> is the input;</li>
<li><span class="math inline">\(z^{l}\)</span> is the weighted input of each hidden layer</li>
<li><span class="math inline">\(a^{l}\)</span> is the output of hidden layer <span class="math inline">\(l\)</span></li>
</ul>
<p>Finally, the derivative is <span class="math inline">\(\frac {dC}{da^{L}} \cdot {\frac {da^{L}}{dz^{L}}}\cdot {\frac {dz^{L}}{da^{L-1}}}\cdot {\frac {da^{L-1}}{dz^{L-1}}}\cdot {\frac {dz^{L-1}}{da^{L-2}}}\cdot \ldots \cdot {\frac {da^{1}}{dz^{1}}}\cdot {\frac {\partial z^{1}}{\partial x}}\)</span></p>
</section>

<section id="ann-and-dnn-training-summarizing" class="title-slide slide level1 center">
<h1>ANN and DNN training: summarizing</h1>
<div class="columns">
<div class="column" style="width:50%;">
<ol type="1">
<li>Loss function → desired goal of the NN
<ul>
<li><em>How</em>?</li>
</ul></li>
<li>Minimize loss function → moving close to the goal
<ul>
<li><em>What does it mean in practice?</em></li>
</ul></li>
<li>Adjusting weights (and bias) of the NN
<ul>
<li><em>Through</em></li>
</ul></li>
<li>Gradient Descent → Optimizers
<ul>
<li>Parameters:
<ul>
<li>Learning rate</li>
<li>Batch size</li>
<li>…</li>
</ul></li>
<li><em>Based on</em></li>
</ul></li>
<li>Backpropagation + Chain Rule
<ul>
<li><em>Therefore</em></li>
</ul></li>
<li>The loss function must be differentiable!</li>
</ol>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model76.png"></p>
<figcaption>Learning rate</figcaption>
</figure>
</div>
<p>The choice of the right value of the learning rate is important!</p>
</div></div>
</section>

<section id="learning-curves" class="title-slide slide level1 center">
<h1>Learning Curves</h1>
<div class="columns">
<div class="column" style="width:50%;">
<p>It is common to create line plots that show epochs along the <em>x</em>-axis and the loss value of the model on the <em>y</em>-axis.</p>
<ul>
<li>2 plots (usually overlapped):
<ul>
<li>One for the training</li>
<li>One for the validation</li>
</ul></li>
<li>These plots are called learning curves.</li>
<li>Loss values (this is an error, then low values are ok for us!)</li>
<li>These plots can help to diagnose whether the model has over-learned (<em>overfitting</em>), under-learned (<em>underfitting</em>), or suitably fits the training dataset.</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model77.png"></p>
<figcaption>Learning curves</figcaption>
</figure>
</div>
<ul>
<li>Usually, at the beginning of the learning, the value of the loss function drops rapidly</li>
<li>Starting of the overfitting</li>
</ul>
</div></div>
</section>

<section id="mlp-in-scikit-learn" class="title-slide slide level1 center">
<h1><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">MLP</a> in Scikit-Learn</h1>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines"><code class="sourceCode python"><span id="cb1-1"><a href=""></a>sklearn.neural_network.MLPClassifier(</span>
<span id="cb1-2"><a href=""></a>    hidden_layer_sizes<span class="op">=</span>(<span class="dv">100</span>,),</span>
<span id="cb1-3"><a href=""></a>    activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb1-4"><a href=""></a>    solver<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb1-5"><a href=""></a>    batch_size<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb1-6"><a href=""></a>    learning_rate<span class="op">=</span><span class="st">"constant"</span>,</span>
<span id="cb1-7"><a href=""></a>    max_iter<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb1-8"><a href=""></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-9"><a href=""></a>    ...</span>
<span id="cb1-10"><a href=""></a>)</span></code></pre></div>
</section>

<section id="developing-ai-systems" class="title-slide slide level1 center">
<h1>Developing AI systems</h1>
<p>It is not just important how well a particular classifier works</p>
<ul>
<li><em>How to develop an AI system</em>?</li>
<li><em>When is it better to use Machine Learning</em>? And <em>Deep Learning</em>?</li>
<li><em>What about hardware for AI</em>?</li>
</ul>
</section>

<section id="how-to-develop-an-ai-project" class="title-slide slide level1 center">
<h1>How to develop an AI project?</h1>
<ul>
<li>We have seen what are the main steps necessary for the realization of an AI project
<ul>
<li><em>Data Collection</em></li>
<li><em>Data Processing</em> (and feature extraction)</li>
<li><em>Model training</em></li>
<li><em>Prediction analysis</em> (through metrics)</li>
</ul></li>
<li>However, there are other important considerations:
<ul>
<li><em>When to address a problem through ML</em>?</li>
<li><em>When to address a problem through DL</em>?</li>
<li><em>What are the hardware resources needed</em>?</li>
<li><em>What are the software resources needed</em>?</li>
</ul></li>
</ul>
</section>

<section id="machine-learning-vs-deep-learning" class="title-slide slide level1 center">
<h1>Machine Learning vs Deep Learning</h1>
<div class="columns">
<div class="column" style="width:55%;">
<table class="caption-top">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Element</th>
<th style="text-align: center;">Machine Learning</th>
<th style="text-align: center;">Deep Learning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>Data</em></td>
<td style="text-align: center;">Large data<br>(~ hundreds)</td>
<td style="text-align: center;">Huge data<br>(~ thousands)</td>
</tr>
<tr class="even">
<td style="text-align: center;"><em>Accuracy</em></td>
<td style="text-align: center;">High accuracy</td>
<td style="text-align: center;">Best accuracy<br>(high-dimensional data)</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><em>Training time</em></td>
<td style="text-align: center;">~minutes</td>
<td style="text-align: center;">~hours, days</td>
</tr>
<tr class="even">
<td style="text-align: center;"><em>Hardware</em></td>
<td style="text-align: center;">CPU</td>
<td style="text-align: center;">GPU</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><em>Features</em></td>
<td style="text-align: center;">Manual</td>
<td style="text-align: center;">Learned</td>
</tr>
<tr class="even">
<td style="text-align: center;"><em>Interpretability</em></td>
<td style="text-align: center;">Good</td>
<td style="text-align: center;">Low</td>
</tr>
</tbody>
</table>
</div><div class="column" style="width:45%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/93.png"></p>
<figcaption>DL vs (classical) ML</figcaption>
</figure>
</div>
</div></div>
</section>

<section id="hardware-for-deep-learning" class="title-slide slide level1 center">
<h1>Hardware for Deep Learning</h1>
<div class="columns">
<div class="column" style="width:70%;">
<p>The training of NN, especially if they are deep, requires specialized hardware:</p>
<ul>
<li>Before starting a project with DL, you need to ask if the company/lab has the necessary hardware</li>
</ul>
<p>Having one or more GPUs available is today a fundamental factor:</p>
<ul>
<li>GPUs are essential for parallelizing (and therefore speeding up) calculations.</li>
<li>As seen, the deeper a network is, the more computational load is introduced</li>
</ul>
<p>To date, Nvidia, a company that dominates the market:</p>
<ul>
<li>The parallelization of the calculations is possible thanks to the CUDA libraries (<em>Compute Unified Device Architecture</em>, the true core business of Nvidia)</li>
<li>Google has started a competition by introducing TPU (<em>Tensor Processor Unit</em>)</li>
</ul>
</div><div class="column" style="width:30%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model105.png"></p>
<figcaption>GPUs</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model106.png"></p>
<figcaption>NVIDIA</figcaption>
</figure>
</div>
</div></div>
</section>

<section id="hardware-purchase-for-dl" class="title-slide slide level1 center">
<h1>Hardware purchase for DL</h1>
<p>In-house solution: the company buys the necessary hardware, it is the direct owner</p>
<ul>
<li>Pros:
<ul>
<li>Extreme freedom of use of hardware</li>
<li>In the long run, it tends to have lower costs</li>
</ul></li>
<li>Cons:
<ul>
<li>Hardware maintenance is required → company needs specialized technicians</li>
<li>Hardware ages (quickly) → necessary investments over time</li>
<li>For large numbers of GPUs:
<ul>
<li>It is necessary to have specific server rooms → temperature and access control</li>
<li>High energy consumption → consumption of the latest generation GPU: ~450W (!)</li>
</ul></li>
<li>The GPU market is quite expensive and volatile:
<ul>
<li>Very few companies involved in the production process → TMSC</li>
<li>Semiconductor shortage</li>
<li>External elements influence the market: mining, wars,…</li>
</ul></li>
</ul></li>
</ul>
</section>

<section id="hardware-for-dl-in-house-vs-external-solutions" class="title-slide slide level1 center">
<h1>Hardware for DL: in-house vs external solutions</h1>
<div class="columns">
<div class="column" style="width:60%;">
<p>External solution: the hardware is rented through the <em>PaaS</em> paradigm (Cloud)</p>
<ul>
<li>Pros:
<ul>
<li>Hardware maintenance is NOT required</li>
<li>NO investment over time is required for hardware upgrades</li>
<li>Dedicated server rooms are NOT required, energy consumption is not borne by the company</li>
</ul></li>
<li>Cons:
<ul>
<li>In the long run, it tends to have higher costs</li>
<li>Cons already seen for cloud-based solutions:
<ul>
<li>Vendor <em>lock-in</em> → it is difficult to escape from the service provider</li>
<li>Who really owns the data?</li>
<li>Privacy issues</li>
</ul></li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./img/neuralnetworks/3%20Model108.png"></p>
<figcaption>COLAB</figcaption>
</figure>
</div>
</div></div>
<p>Examples:</p>
<ul>
<li><a href="https://cloud.google.com/products/calculator/">https://cloud.google.com/products/calculator/</a></li>
<li><a href="https://www.leadergpu.com/#chose-best">https://www.leadergpu.com/#chose-best</a></li>
<li><a href="https://buomsoo-kim.github.io/colab/2020/03/15/Google-newly-launches-colab-pro.md/">https://buomsoo-kim.github.io/colab/2020/03/15/Google-newly-launches-colab-pro.md/</a></li>
<li><a href="https://calculator.aws/#/addService/EC2">https://calculator.aws/#/addService/EC2</a></li>
</ul>
</section>

<section id="section-1" class="title-slide slide level1 center">
<h1></h1>
<div class="columns">
<div class="column" style="width:50%;">
<p><img data-src="./img/neuralnetworks/3%20Model107.png"></p>
</div><div class="column" style="width:50%;">
<p><img data-src="./img/neuralnetworks/95.png"></p>
</div></div>
<p>Demos</p>
<ul>
<li><a href="https://playground.tensorflow.org">Playground tensorflow</a></li>
<li><a href="https://cs.stanford.edu/people/karpathy/convnetjs/">Convnetjs</a></li>
</ul>
</section>

<section id="references" class="title-slide slide level1 smaller scrollable">
<h1>References</h1>

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-hastad1986almost" class="csl-entry" role="listitem">
Hastad, John. 1986. <span>“Almost Optimal Lower Bounds for Small Depth Circuits.”</span> In <em>Proceedings of the Eighteenth Annual ACM Symposium on Theory of Computing</em>, 6–20.
</div>
<div id="ref-kidger2020universal" class="csl-entry" role="listitem">
Kidger, Patrick, and Terry Lyons. 2020. <span>“Universal Approximation with Deep Narrow Networks.”</span> In <em>Conference on Learning Theory</em>, 2306–27. PMLR.
</div>
<div id="ref-mcculloch1943logical" class="csl-entry" role="listitem">
McCulloch, Warren S, and Walter Pitts. 1943. <span>“A Logical Calculus of the Ideas Immanent in Nervous Activity.”</span> <em>The Bulletin of Mathematical Biophysics</em> 5: 115–33.
</div>
</div>
</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Matteo Francia - Machine Learning and Data Mining (Module 2) - A.Y. 2024/25</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="05-neuralnetworks_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="05-neuralnetworks_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="05-neuralnetworks_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="05-neuralnetworks_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="05-neuralnetworks_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="05-neuralnetworks_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="05-neuralnetworks_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="05-neuralnetworks_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="05-neuralnetworks_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="05-neuralnetworks_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    <script>videojs(video_shortcode_videojs_video1);</script>
    <script>videojs(video_shortcode_videojs_video2);</script>
    <script>videojs(video_shortcode_videojs_video3);</script>
    <script>videojs(video_shortcode_videojs_video4);</script>
    

</body></html>