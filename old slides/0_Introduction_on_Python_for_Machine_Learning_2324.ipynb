{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Opening a file and read the content**\n",
        "In this block, we learn how to open a file with Python and how to read the content.\n",
        "\n",
        "**It is absolutely recommended to read the documentation relating to the functions and methods used!**\n",
        "Usually, it is sufficient type on Google the name of the function (and eventually the name of the library used).\n",
        "\n"
      ],
      "metadata": {
        "id": "VaTYWpBnXs-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Locate the file we want to use.\n",
        "The file is `shapes.txt`: this is the file of the dataset that we are going to use in our exercises.\n",
        "\n",
        "There are two options to use the file in a Colab project:\n",
        "- Upload the file through the Colab GUI (temporary upload!);\n",
        "- Upload the file on your Google Drive (you have to use the same Google account that you use with Colab)). Then, it is necessary to mount the drive in your Colab machine (use the \"Mount Drive\" button.);\n",
        "- Use the following code snippet\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "Fdjrwg0N-36p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "AozF-BXlGOTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default upload location of the file is in `/content`in the Google virtual machine."
      ],
      "metadata": {
        "id": "RDH0hW6Vwx-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/shapes.txt' # equivalent to: 'shapes.txt'"
      ],
      "metadata": {
        "id": "e4QKh5FL6hn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First way to open a file\n",
        "Remember to close the file once read!\n",
        "<br>\n",
        "**Tools**:\n",
        "\n",
        "* `open(<path>, <mode>)`: open the file located in the `path`, for reading, writing, ect. depending by the `mode`."
      ],
      "metadata": {
        "id": "F7D93e5M6cqS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bic2ENrvXhqI"
      },
      "outputs": [],
      "source": [
        "f = open(file_path, 'r')\n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "print('Read {} lines'.format(len(lines)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second way to open a file\n",
        "In this case, the file is auotomatically closed."
      ],
      "metadata": {
        "id": "CKTh0ir86mNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "print('Read {} lines'.format(len(lines)))"
      ],
      "metadata": {
        "id": "9w_qIc816n6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **File content processing**\n",
        "In this block, we learn how to process the content of a file."
      ],
      "metadata": {
        "id": "FgDkO7br7AzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the first two lines\n",
        "Note that each line has the following format: `image_name` `coordinates`.\n",
        "Coordinates are organized as follows: $p^1_x \\quad p^1_y \\quad p^2_x \\quad p^2_y \\quad ... \\quad p^n_x \\quad p^n_x$,  $\\quad 3 \\leq n \\leq 4$, since we have the classes:\n",
        "\n",
        "*   Triangle\n",
        "*   Rectangle\n",
        "*   Square\n",
        "*   Rhombus\n",
        "\n",
        "Example: `0_triangle.png 114 221 152 189 223 30`  \n",
        "\n",
        "**Tools**:\n",
        "- `strip()`: removes both the leading and the trailing characters.\n",
        "- `split()`: breaks up a string at the specified separator and returns a list of strings.\n",
        "- Slicing: `list[start:stop:step]`\n",
        "\n",
        "Examples:\n",
        "\n",
        "*   `a[start:stop]  # items start through stop-1`\n",
        "*   `a[start:]      # items start through the rest of the array`\n",
        "*   `a[:stop]       # items from the beginning through stop-1`\n",
        "*   `a[:]           # a copy of the whole array`\n",
        "*   `a[-1]    # last item in the array`\n",
        "*   `a[-2:]   # last two items in the array`\n",
        "*   `a[:-2]   # everything except the last two items`\n",
        "*    `a[::-1]    # all items in the array, reversed`"
      ],
      "metadata": {
        "id": "zt74aKE_7XT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for line in lines[:2]:\n",
        "\n",
        "    print(\"Raw content:\", line)\n",
        "\n",
        "    content = line.strip()\n",
        "    print(\"Content after strip:\", content)\n",
        "\n",
        "    content = content.split(' ')\n",
        "    print(\"Content after split:\", content)\n",
        "\n",
        "    # now the content is a list with the splitted elements\n",
        "    image_name = content[0]   # the image name is in the first position\n",
        "    coordinates = content[1:] # coordinates in the following part\n",
        "\n",
        "    # print the content\n",
        "    print('Name:', image_name, 'Coords:', coordinates)\n",
        "    print('---')"
      ],
      "metadata": {
        "id": "AkjpEdlL7J7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the element in the list are strings. We must convert these strings in integers (`int`). These integers are then saved in a list.\n",
        "\n",
        "**Tools**:\n",
        "- List comprehension: `[expression for item in list]`"
      ],
      "metadata": {
        "id": "XRi9VA5U-OEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Type of the coordinates:', type(coordinates[0]))\n",
        "coordinates = [int(x) for x in coordinates]\n",
        "print('Name:', image_name, 'Coords:', coordinates)\n",
        "print('Type of the coordinates:', type(coordinates[0]))"
      ],
      "metadata": {
        "id": "2w3TPSIP7Op7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding the directory organization of the dataset**"
      ],
      "metadata": {
        "id": "yl9HBDnG_AuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the directory of the dataset that we are going to use in our exercises.\n",
        "\n",
        "Also in that case, we have many options to upload the content:\n",
        "\n",
        "1.   Upload the `.zip` file containing the *Euclid* dataset from the left panel (first icon on the top bar)\n",
        "\n",
        "2.   Unzip the file using the following comand. Dataset folders will appear in `/content/sample_data`"
      ],
      "metadata": {
        "id": "ajZO06EoM5ZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q Euclid_dataset.zip -d /content/dataset"
      ],
      "metadata": {
        "id": "EkXgqjmi2wn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A new folder is in your virtual machine (click the \"Reload\" icon if you do not see it).\n",
        "\n",
        "You can directly upload the dataset folder on your Google Drive account (you may have mounted the Drive before)."
      ],
      "metadata": {
        "id": "3aDzFK402xyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define the path of the dataset"
      ],
      "metadata": {
        "id": "-Zw7CIp1N8OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/dataset/Euclid_dataset' # /content/driver/... if the dataset is in the Drive folder"
      ],
      "metadata": {
        "id": "i-Cf96H9Dz2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count the number of images in each dataset folder\n",
        "\n",
        "**Tools**:\n",
        "\n",
        "- `glob(<pathname>)`: return a possibly-empty list of path names that match pathname. You can also use wildcards (`*`,` ?`, `[ranges]`) apart from exact string search to make path retrieval more simple and convenient.\n",
        "- `os.path.join`: join one or more path components\n",
        "\n"
      ],
      "metadata": {
        "id": "Cur03JY4ABZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of the `join` command."
      ],
      "metadata": {
        "id": "Lw9GmuqZNFjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import join\n",
        "s1 = 'path1'\n",
        "s2 = 'path2'\n",
        "s3 = 'path3'\n",
        "print('Final path:', join(s1, s2, s3))"
      ],
      "metadata": {
        "id": "w1ZrJoLZDWS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of the `glob` command"
      ],
      "metadata": {
        "id": "SXboOdIYNKD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "# we list the directories inside the dataset main directory\n",
        "elements = glob(join(dataset_path, '*'))\n",
        "print(len(elements), elements)\n"
      ],
      "metadata": {
        "id": "11fSMrAgDvNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are ready to count the number of images in each folder of the dataset."
      ],
      "metadata": {
        "id": "a4Kctnb-NQ8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shapes = ['triangle', 'rectangle', 'square', 'rhombus']\n",
        "for shape in shapes:\n",
        "    images = glob(join(dataset_path, shape, '*.png'))\n",
        "    print('Total amount of {}: \\t {}'.format(shape, len(images)))"
      ],
      "metadata": {
        "id": "Exr2ACT0-tN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute the total amount of images."
      ],
      "metadata": {
        "id": "K_Y3AjNJNW41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = glob(join(dataset_path, '*', '*.png'))\n",
        "print('Total amount of images: {}'.format(len(images)))\n",
        "print('List of images:', sorted(images))"
      ],
      "metadata": {
        "id": "hg18sQmmEhNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "Read the content of the file `shapes.txt` and **accumulate** the image names and coordinates (integers) in two different lists, named `image_names` and `shape_coordinates`. Output the final length of the two lists."
      ],
      "metadata": {
        "id": "OQlZB3AKNbdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write the code here"
      ],
      "metadata": {
        "id": "W4tkbP8yITed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Images**\n",
        "Now, it's time to play with images!"
      ],
      "metadata": {
        "id": "m418iw0xEuQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading and showing images\n",
        "We use the *OpenCV* library to handle images.\n",
        "\n",
        "Tools:\n",
        "-   `cv2.imread()`: opens an image. Use: `imread(<name>, bw/color)`\n",
        "-   `cv2_imshow()`: shows an image. (original cv2 function is `cv2.imshow()`)\n",
        "-   `cv2.resize()`: resizes an image."
      ],
      "metadata": {
        "id": "wW8teUIfNwmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for image in images[::100]:\n",
        "    img = cv2.imread(image, 0) # 0: bw, 1: color\n",
        "    img = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
        "    cv2_imshow(img)"
      ],
      "metadata": {
        "id": "ukgYgm4UEtux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing images\n",
        "Remember that images are numbers, organized in $M \\times N \\times C$ matrices, where $M$ is the number of columns, $N$ is the number of rows and $C$ is the number of channels ($C=1$ for black and white images, $C=3$ for RGB images)."
      ],
      "metadata": {
        "id": "S95w_LDRP2TI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the *Numpy* library.\n",
        "\n",
        "**Tools**:\n",
        "-   `np.max()`: returns the maximum along a given axis.\n",
        "-   `np.min()`: returns the minimum along a given axis.\n",
        "-   `np.mean()`: returns the average value along a given axis.\n",
        "-   `np.std()`: returns the standard deviation along a given axis."
      ],
      "metadata": {
        "id": "uXLg1mLt6Sul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "image_name = image_names[random.randint(0, len(image_names))]\n",
        "\n",
        "shape = image_name.split('_')[1][:-4]\n",
        "print(join(dataset_path, shape, image_name))\n",
        "\n",
        "img = cv2.imread(join(dataset_path, shape, image_name), 1)\n",
        "print('BGR image (3 channels) shape:', img.shape)\n",
        "\n",
        "img = cv2.imread(join(dataset_path, shape, image_name), 0)\n",
        "print('BW image (1 channel) shape:', img.shape)\n",
        "\n",
        "# compute some values\n",
        "print('Max value:', np.max(img))\n",
        "print('Min value:', np.min(img))\n",
        "print('Avg value: {:.3f}'.format(np.mean(img)))\n",
        "print('Std value: {:.3f}'.format(np.std(img)))\n"
      ],
      "metadata": {
        "id": "o0E1R6piG_tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "Z4R_Js0qf1Qf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Normalization** (also called min max scaling)\n",
        "\n",
        "*   Values are shifted and rescaled so that they end up ranging from 0 to 1\n",
        "*   We do this by subtracting the min value and dividing by the max minus the min\n",
        "\n",
        "**Data Standardization**\n",
        "\n",
        "*   We subtract the mean value, and then we divide by the standard deviation\n",
        "*   The resulting values will have zero mean and unit variance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QCbjAoS_giUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "Apply data normalization and standardization on the first image of the Euclid dataset. Print the values `min, max, avg and std` of the resulting image."
      ],
      "metadata": {
        "id": "Y8nh1lH66dS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write the code here"
      ],
      "metadata": {
        "id": "Lpk4SPtGf3Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### From coordinates, to lines and points\n",
        "We are going to draw coordinates and shapes in images using OpenCV library.\n",
        "It is a useful activity in order to better understand our data available in the dataset."
      ],
      "metadata": {
        "id": "rEupy5GBP99Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tools**:\n",
        "-   `cv2.circle()`: draws a circle on any image.\n",
        "-   `cv2.putText()`: draw a text string on any image.\n",
        "-   `cv2.line()`: draws a line on any image."
      ],
      "metadata": {
        "id": "ygAfet1Q6_Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_coords = True\n",
        "write_text = True\n",
        "draw_shapes = True\n",
        "\n",
        "for c in shape_coordinates[::200]:\n",
        "\n",
        "    white_paper = np.ones((224, 224, 3)) * 255\n",
        "\n",
        "    if draw_coords:\n",
        "        # draw vertices\n",
        "        cv2.circle(white_paper, (c[0], c[1]), 4, (255, 0, 0), -1)\n",
        "        cv2.circle(white_paper, (c[2], c[3]), 4, (255, 0, 0), -1)\n",
        "        cv2.circle(white_paper, (c[4], c[5]), 4, (255, 0, 0), -1)\n",
        "        if len(c) > 6:\n",
        "            cv2.circle(white_paper, (c[6], c[7]), 4, (255, 0, 0), -1)\n",
        "\n",
        "    if write_text:\n",
        "        # write text\n",
        "        cv2.putText(white_paper, 'P1', (c[0], c[1]), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0))\n",
        "        cv2.putText(white_paper, 'P2', (c[2], c[3]), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0))\n",
        "        cv2.putText(white_paper, 'P3', (c[4], c[5]), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0))\n",
        "        if len(c) > 6:\n",
        "            cv2.putText(white_paper, 'P4', (c[6], c[7]), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0))\n",
        "\n",
        "    if draw_shapes:\n",
        "        # draw shapes\n",
        "        cv2.line(white_paper, (c[0], c[1]), (c[2], c[3]), (0, 0, 0), 1)\n",
        "        cv2.line(white_paper, (c[2], c[3]), (c[4], c[5]), (0, 0, 0), 1)\n",
        "        if len(c) == 6:\n",
        "            cv2.line(white_paper, (c[4], c[5]), (c[0], c[1]), (0, 0, 0), 1)\n",
        "        else:\n",
        "            cv2.line(white_paper, (c[4], c[5]), (c[6], c[7]), (0, 0, 0), 1)\n",
        "            cv2.line(white_paper, (c[6], c[7]), (c[0], c[1]), (0, 0, 0), 1)\n",
        "\n",
        "    print()\n",
        "    cv2_imshow(white_paper)"
      ],
      "metadata": {
        "id": "JRUrmVtHMGYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homework\n",
        "For each element of the Euclid dataset, compute:\n",
        "\n",
        "*   **Perimeter**\n",
        "*   **Area**\n",
        "*   **Centroid** (barycenter)\n",
        "\n",
        "Save the results in a `results.txt` file. Each line of the file must correspond to the same line of the `shape.txt` file and must follows this format:\n",
        "\n",
        "`<perimeter> <area> <(x,y)>`\n",
        "\n",
        "Example:\n",
        "423 433.5 (234,456)\n",
        "\n",
        "Upload the `results.txt` file on Virtuale (*Homework #1*).\n",
        "\n"
      ],
      "metadata": {
        "id": "wVQ7lo_QVX5s"
      }
    }
  ]
}