{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFjJxN88-_Xw"
      },
      "source": [
        "# **Classification with Machine Learning**\n",
        "\n",
        "In this lesson, we learn how to solve a classification problem through Machine Learning ensemble classifiers, *i.e.* models that are able to automatically learn how to solve a problem.\n",
        "\n",
        "**It is absolutely recommended to read the documentation relating to the functions and methods used!**\n",
        "Usually, it is sufficient typing on Google the name of the function (and eventually the name of the library used)."
      ],
      "id": "wFjJxN88-_Xw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQx0egnB_ZTb"
      },
      "source": [
        "Import some libraries\n",
        "In particular, `sklearn` is the library for the Machine Learning stuff!"
      ],
      "id": "FQx0egnB_ZTb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d39427db-e6d8-49d0-a395-6d96344edaba"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "id": "d39427db-e6d8-49d0-a395-6d96344edaba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKOGvTBK_dPb"
      },
      "source": [
        "### Functions and Classes\n"
      ],
      "id": "jKOGvTBK_dPb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI3jL4Kd_ksT"
      },
      "source": [
        "`get_labels()` is a function that receives a name (`string`) and returns the class (`int`), following this:\n",
        "\n",
        "*   Triangle: 0\n",
        "*   Rectangle: 1\n",
        "*   Square: 2\n",
        "*   Rhombus: 3\n",
        "\n",
        "Example: 0_triangle.png â†’ 0"
      ],
      "id": "xI3jL4Kd_ksT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJitaZqSPjXR"
      },
      "outputs": [],
      "source": [
        "def get_labels(name):\n",
        "    if 'triangle' in name:\n",
        "        return 0\n",
        "    elif 'square' in name:\n",
        "        return 1\n",
        "    elif 'rectangle' in name:\n",
        "        return 2\n",
        "    elif 'rhombus' in name:\n",
        "        return 3\n",
        "    else:\n",
        "        raise NotImplementedError('Not existing class!')"
      ],
      "id": "vJitaZqSPjXR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGN5pf8jAtJU"
      },
      "source": [
        "`prepare__data()` is a function that prepare the data for the computation.\n",
        "Specifically, returns two lists: `coordinates` and `labels`.\n",
        "In this exercise, we exclude `triangles` from classes for simplicity."
      ],
      "id": "FGN5pf8jAtJU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXxyK0sRPmOW"
      },
      "outputs": [],
      "source": [
        "def prepare_data(lines):\n",
        "    labels = []\n",
        "    coordinates = []\n",
        "\n",
        "    for line in lines:\n",
        "        content = line.split()\n",
        "\n",
        "        # let's exclude triangles\n",
        "        if 'triangle' not in content[0]:\n",
        "            # create label\n",
        "            labels.append(get_labels(content[0]))\n",
        "\n",
        "            # coordinates\n",
        "            coordinates.append([float(x) for x in content[1:]])\n",
        "\n",
        "    return coordinates, labels"
      ],
      "id": "NXxyK0sRPmOW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM7mgZQxBub7"
      },
      "source": [
        "### Body of the solution\n",
        "Upload the file `shapes.txt`.\n",
        "Open the dataset file `shapes.txt` and read the content"
      ],
      "id": "zM7mgZQxBub7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9UfwAokQcMJ"
      },
      "outputs": [],
      "source": [
        "dataset_file_path = 'shapes.txt'\n",
        "with open(dataset_file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    print('Read {} lines'.format(len(lines)))"
      ],
      "id": "F9UfwAokQcMJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL_HkwmsCCQ0"
      },
      "source": [
        "We **shuffle** the data to change the initial order.\n",
        "It is important in order to have a train and a validation set with all classes.\n",
        "\n",
        "**Tools**:\n",
        "-    `np.random.shuffle()`: modify a sequence in-place by shuffling its contents."
      ],
      "id": "nL_HkwmsCCQ0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXKiO_paQjI4"
      },
      "outputs": [],
      "source": [
        "print('Before shuffling: {}'.format(lines[:10]))\n",
        "np.random.shuffle(lines)\n",
        "print('Before shuffling: {}'.format(lines[:10]))"
      ],
      "id": "SXKiO_paQjI4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKpyTz4HCLcC"
      },
      "source": [
        "Differently from the previous exercitation, **in this case it is essential to have a training, validation and test sets**.\n",
        "Training data are used to train the model, while the validation split is used to assess performance.\n",
        "\n",
        "Here, we use validation and test set as synonymous, since we do not have a real test set.\n",
        "\n",
        "We put **20% of data in training, 20% in validation**, and the remaining **60% in the test set**."
      ],
      "id": "wKpyTz4HCLcC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fipgi_u-QnlP"
      },
      "outputs": [],
      "source": [
        "trainset = lines[:int(0.2*len(lines))]\n",
        "valset = lines[int(0.2*len(lines)):int(0.4*len(lines))]\n",
        "testset = lines[int(0.4*len(lines)):]\n",
        "print('Total: {} splitted in Train: {}, Val: {} and Test: {}'.format(len(lines), len(trainset), len(valset), len(testset)))"
      ],
      "id": "fipgi_u-QnlP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79v-BHLvLvMU"
      },
      "source": [
        "There is also another way to create the train/val/est splits.\n",
        "\n",
        "**Tools**:\n",
        "\n",
        "*   `train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)`: splits arrays or matrices into random train and test subsets. It is also possible to shuffle data.\n",
        "\n"
      ],
      "id": "79v-BHLvLvMU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG_jr9O7LsNp"
      },
      "outputs": [],
      "source": [
        "# to apply this method we need two different lists: X (data) and y (labels)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "id": "HG_jr9O7LsNp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x4XwcitCwig"
      },
      "source": [
        "From this moment, we will have three sets: train, validation and test set.\n",
        "\n",
        "A single datapoint belongs only to one, **these three sets are completely disjointed**.\n",
        "\n",
        "It is important to keep them separated!"
      ],
      "id": "4x4XwcitCwig"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynofm8YswEsN"
      },
      "source": [
        "Apply **bootstrapping** (random sampling with replacement)"
      ],
      "id": "Ynofm8YswEsN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf2KafT6v_-W"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "set_number = 3\n",
        "\n",
        "trainsets = []\n",
        "\n",
        "for i in range(set_number):\n",
        "  trainsets.append(random.choices(trainset, k=int(len(trainset)/set_number)))\n",
        "\n",
        "for i in range(set_number):\n",
        "  print('{} subsets with {} elements'.format(i, len(trainsets[i])))"
      ],
      "id": "Kf2KafT6v_-W"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbKcMlOWQtTn"
      },
      "outputs": [],
      "source": [
        "trains_x_y = []\n",
        "\n",
        "for i in range(set_number):\n",
        "  trains_x_y.append(prepare_data(trainsets[i]))\n",
        "\n",
        "val_x, val_y = prepare_data(valset)\n",
        "test_x, test_y = prepare_data(testset)\n",
        "\n",
        "for i in range(set_number):\n",
        "  print('Train {}: {}'.format(i, len(trains_x_y[i][0])))\n",
        "\n",
        "print('Val: {} and Test: {}'.format(len(val_x), len(test_x)))"
      ],
      "id": "SbKcMlOWQtTn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1My56AGDIXj"
      },
      "source": [
        "### Classifier\n",
        "Here, we define what classifier we are going to use to solve our classification problem. Let's use the SVM implementation of the `sklearn` library.\n"
      ],
      "id": "u1My56AGDIXj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF5xpgPfQ36w"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifiers = []\n",
        "\n",
        "for i in range(set_number):\n",
        "  classifiers.append(DecisionTreeClassifier())\n",
        "\n",
        "print('{} classifiers declared'.format(len(classifiers)))"
      ],
      "id": "ZF5xpgPfQ36w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLkeVCUxDcIl"
      },
      "source": [
        "### Training\n",
        "Now we are ready for the training!\n",
        "With `sklearn` library is tremendously simple, we just need training data (`train_x` and the related labels `train_y`) and pass them to the classifier.\n",
        "\n",
        "**Tools**:\n",
        "-   `model.fit()`: fit the provided model with training data."
      ],
      "id": "RLkeVCUxDcIl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaoAX6iwQ5hd"
      },
      "outputs": [],
      "source": [
        "for iteration, (clf, data) in enumerate((zip(classifiers, trains_x_y))):\n",
        "  print('Training {} classifier'.format(iteration), end=\", \")\n",
        "  clf.fit(data[0], data[1])\n",
        "  print('done!')"
      ],
      "id": "uaoAX6iwQ5hd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNNuHP0_hHYb"
      },
      "source": [
        "### Test\n",
        "\n",
        "It's time to test the trained model.\n",
        "We skip the validation for simplicity.\n",
        "\n"
      ],
      "id": "eNNuHP0_hHYb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmdAmrAfhKKi"
      },
      "outputs": [],
      "source": [
        "pred_y = []\n",
        "\n",
        "for x, y in zip(test_x, test_y):\n",
        "  # votes for all classes\n",
        "  votes = [0, 0, 0, 0]\n",
        "  for clf in classifiers:\n",
        "    x = np.array(x)\n",
        "    x = x.reshape(1, -1)\n",
        "    prediction = clf.predict(x)\n",
        "    # here, votes are accumulated\n",
        "    votes[int(prediction)] += 1\n",
        "  # here, the most voted is selected\n",
        "  pred_y.append(np.argmax(votes))\n",
        "\n",
        "print(pred_y)\n",
        "print('Final Accuracy: {:.3f}'.format(accuracy_score(test_y, pred_y)))"
      ],
      "id": "SmdAmrAfhKKi"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}