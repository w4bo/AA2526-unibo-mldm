::Q1::
Which of the following is the main goal of the 'Data Preparation' phase in CRISP-DM?{
    ~Evaluating model performance
    ~Building predictive models
    =Cleaning, transforming, and organizing data for analysis
    ~Gathering business requirements
}

::Q2::
What is a common technique used to handle missing data in the dataset?{
    =Imputation
    ~Scaling
    ~Dimensionality reduction
    ~Feature selection
}

::Q3::
Which method is commonly used to normalize numerical data during the Data Preparation phase?{
    ~Label encoding
    =Min-max scaling
    ~Cross-validation
    ~Binarization
}

::Q4::
When handling categorical variables in a dataset, which technique converts categories into numerical form without assuming any ordinal relationship?{
    ~PCA (Principal Component Analysis)
    ~K-means clustering
    ~Z-score normalization
    =One-hot encoding
}

::Q5::
What is the purpose of feature selection in the Data Preparation phase?{
    ~To increase the number of attributes for the model
    ~To improve the performance of the data storage systems
    =To select the most relevant features that contribute to the modelâ€™s accuracy
    ~To reduce model complexity without sacrificing performance
}

::Q6::
Which of the following data transformation techniques is most useful for dealing with skewed data distributions?{
    =Log transformation
    ~K-fold cross-validation
    ~Normalization
    ~One-hot encoding
}

::Q7::
During the Data Preparation phase, outlier detection is important because:{
    ~Outliers improve the accuracy of classification models
    =Outliers can heavily influence model performance, especially for algorithms sensitive to extreme values
    ~Outliers always need to be removed from the dataset
    ~Outliers have no significant impact on machine learning models
}

::Q8::
When combining multiple data sources, what is the main challenge in the Data Preparation phase?{
    =Ensuring that data from different sources has consistent formats and meanings (data integration)
    ~Avoiding data redundancy
    ~Training a model on multiple datasets simultaneously
    ~Developing an algorithm to merge the data
}

::Q9::
In feature engineering, why might you create interaction terms between features?{
    ~To introduce polynomial relationships between features
    ~To reduce the number of features in the dataset
    ~To remove noise from the data
    =To capture the relationship between two or more variables that may improve the model's predictive power
}

::Q10::
Which of the following is NOT typically a part of the Data Preparation phase?{
    =Hyperparameter tuning
    ~Feature transformation and encoding
    ~Dimensionality reduction (e.g., PCA)
    ~Data cleaning and handling missing values
}
