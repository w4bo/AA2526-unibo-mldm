{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730b0626",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/w4bo/AA2425-unibo-mldm/blob/master/slides/lab-05-ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9e63b",
   "metadata": {},
   "source": [
    "---\n",
    "subtitle: \"Modeling and Evaluation\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3f6fd",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "<img src=\"./img/crispdm_me.svg\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a621068",
   "metadata": {
    "id": "9a621068"
   },
   "source": [
    "# Modeling\n",
    "\n",
    "Machine Learning is the science (and art) of programming computers so they can learn from data\n",
    "\n",
    "> **Machine Learning** is the field of study that gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959)\n",
    "\n",
    "> A computer program is said to **learn** from *experience E with respect to some task T and some performance measure P*, *if its performance on T, as measured by P, improves with experience E* (Tom Mitchell, 1997)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609777a",
   "metadata": {},
   "source": [
    "# Under and overfitting\n",
    "\n",
    ":::: {.columns}\n",
    "::: {.column width=50%}\n",
    "\n",
    "![https://xkcd.com/2048/](img/modeling/slides390.png)\n",
    "\n",
    ":::\n",
    "::: {.column width=50%}\n",
    "\n",
    "![https://xkcd.com/605/](img/modeling/slides391.png)\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0038c",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "\n",
    "Machine learning is not just the application of some algorithms to get the best accuracy...\n",
    "\n",
    "- You need to understand **why** a model is behaving in a certain way!\n",
    "- This is very important, **especially** for the exam!\n",
    "- Do not stop at the first (good) result, questioning your algorithm/pipeline is essential!\n",
    "- Do not rely on external code without knowing what the code is doing\n",
    "    - Remember, if you cannot explain your code the exam is not passed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66748e0c",
   "metadata": {
    "id": "66748e0c"
   },
   "source": [
    "# Types of machine learning\n",
    "\n",
    "There are many types of Machine Learning algorithms\n",
    "\n",
    "We can classify them in broad categories, based on the following criteria:\n",
    "\n",
    "- Whether they are *trained with human supervision*\n",
    "    - Supervised, unsupervised, semi-supervised, and reinforcement learning\n",
    "- Whether they can *learn incrementally*\n",
    "    - Online, batch learning\n",
    "- Whether *they compare new to known data points, or detect patterns/models in the training*\n",
    "    - Instance-based, model-based learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae284be",
   "metadata": {
    "id": "4ae284be"
   },
   "source": [
    "# [scikit-learn](https://scikit-learn.org/stable/index.html): Machine Learning in Python\n",
    "\n",
    "- This library is built upon NumPy, SciPy and Matplotlib\n",
    "    - Open source and commercially usable\n",
    "- Covers many algorithms\n",
    "    - *Supervised Learning*: linear regression, support vector machine, etc.\n",
    "    - *Unsupervised Learning*: clustering, factor analysis, PCA, neural networks, etc.\n",
    "    - *Validation*: check the accuracy of supervised models on unseen data\n",
    "    - *Feature extraction*: extract the features from data to define the attributes in image and text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1c257",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:19.511585Z",
     "iopub.status.busy": "2024-10-08T14:37:19.511585Z",
     "iopub.status.idle": "2024-10-08T14:37:20.471763Z",
     "shell.execute_reply": "2024-10-08T14:37:20.471763Z"
    },
    "id": "80e1c257",
    "outputId": "19814ad4-7ef0-47a6-c339-2729b5be8854"
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "\n",
    "print(sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec05870",
   "metadata": {},
   "source": [
    "# scikit-learn\n",
    "\n",
    "![Algorithms from sklearn](./img/modeling/sklearn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885356d",
   "metadata": {
    "id": "3885356d"
   },
   "source": [
    "# Estimator\n",
    "\n",
    "**Estimator**: a consistent interface for a wide range of ML applications\n",
    "\n",
    "- An algorithm that learns from the data (fitting the data) is an estimator\n",
    "- It can be used with any of the algorithms like classification, regression, and clustering\n",
    "\n",
    "All the parameters can be set when creating the estimator\n",
    "\n",
    "```python\n",
    "estimator = Estimator(param1=1, param2=2)\n",
    "estimator.param1\n",
    "```\n",
    "\n",
    "All estimator objects expose a `.fit()` method that performs the training of the algorithm\n",
    "\n",
    "```python\n",
    "estimator.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Once the estimator is fitted, all the estimated parameters will be the attributes of the estimator object ending by an underscore\n",
    "\n",
    "```python\n",
    "estimator.estimated_param_\n",
    "```\n",
    "\n",
    "Finally, you can `.predict()` unseen data\n",
    "\n",
    "```python\n",
    "y_pred = estimator.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec30efe",
   "metadata": {
    "id": "8ec30efe"
   },
   "source": [
    "# scikit-learn in action\n",
    "\n",
    "Choose a model by importing the appropriate estimator class from Scikit-learn (e.g., a decision tree)\n",
    "\n",
    "```python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "```\n",
    "\n",
    "Choose the model's hyperparameters\n",
    "\n",
    "```python\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "```\n",
    "\n",
    "Fit the model by calling `.fit()` method of the model instance\n",
    "\n",
    "```python\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Applying the model to new data using the `.predict()` method to predict the labels for unknown data.\n",
    "\n",
    "```python\n",
    "y_pred = clf.predict(X_test)\n",
    "```\n",
    "\n",
    "Evaluate the performance\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28525fa",
   "metadata": {
    "id": "d28525fa"
   },
   "source": [
    "# Supervised learning\n",
    "\n",
    "We focus on **supervised learning tasks**\n",
    "\n",
    "- The training *includes the desired solutions* (i.e., labels)\n",
    "- *Classification*\n",
    "    - Approximating a mapping function (`f`) from input variables (`X`) to discrete output variables (`y`)\n",
    "    - The mapping function predicts the class or category for a given observation\n",
    "    - E.g., a spam filter is trained with many example emails along with their class (`spam` or `ham`)\n",
    "- *Regression*\n",
    "    - Approximating a mapping function (`f`) from input variables (`X`) to a continuous output variableÂ (`y`)\n",
    "    - A continuous output variable is a real-value, such as an integer or floating-point value\n",
    "    - E.g., predict the `price` of a car given a set of features (`mileage`, `age`, `brand`, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8311dd",
   "metadata": {
    "id": "ca8311dd"
   },
   "source": [
    "# Training and test sets\n",
    "\n",
    "For a supervised learning problem we need:\n",
    "\n",
    "- *Input data* along with labels\n",
    "- Split data between *test and training set*\n",
    "    - How?\n",
    "\n",
    "Scikit-learn uses data in the form of N-dimensional matrix\n",
    "\n",
    "- Data as a feature matrix `X` (e.g., a Pandas DataFrame)\n",
    "    - The samples represent the individual objects described by the dataset (e.g., a `person`)\n",
    "    - The features describe each sample in a quantitative manner (e.g., `age` and `height`)\n",
    "- Data as target array `y` (e.g., a Pandas Series)\n",
    "    - Along with features matrix, we also have the target array (label)\n",
    "\n",
    "How do we distinguish target and feature columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901f323",
   "metadata": {},
   "source": [
    "# Datasets in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54858f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "\n",
    "for dataset in [func for func in dir(datasets) if 'load_' in func]:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb00a87",
   "metadata": {},
   "source": [
    "# The `Iris` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y-nsPIhDQe89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:20.473817Z",
     "iopub.status.busy": "2024-10-08T14:37:20.473817Z",
     "iopub.status.idle": "2024-10-08T14:37:20.630089Z",
     "shell.execute_reply": "2024-10-08T14:37:20.630089Z"
    },
    "id": "Y-nsPIhDQe89",
    "outputId": "d019e408-35e4-4d21-d78a-9b92b6784e2a"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()  # Load the iris dataset\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)  # Create a DataFrame with the iris data\n",
    "df['species'] = iris.target  # Add the species column to the DataFrame\n",
    "# df['species'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ci9b1QZ7N1oq",
   "metadata": {
    "id": "ci9b1QZ7N1oq"
   },
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ohmh7Kc8Nvm7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:20.632093Z",
     "iopub.status.busy": "2024-10-08T14:37:20.632093Z",
     "iopub.status.idle": "2024-10-08T14:37:20.637676Z",
     "shell.execute_reply": "2024-10-08T14:37:20.637676Z"
    },
    "id": "ohmh7Kc8Nvm7",
    "outputId": "3a9f740a-1006-4b5d-9d44-ff192314d6a1"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5_PuuFSBN30K",
   "metadata": {
    "id": "5_PuuFSBN30K"
   },
   "source": [
    "# Training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fOKkpeA2NeEs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:20.639679Z",
     "iopub.status.busy": "2024-10-08T14:37:20.639679Z",
     "iopub.status.idle": "2024-10-08T14:37:20.680987Z",
     "shell.execute_reply": "2024-10-08T14:37:20.680987Z"
    },
    "id": "fOKkpeA2NeEs"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = df.drop(\"species\", axis=1)\n",
    "y = df[\"species\"]\n",
    "seed=42  # Setup random seed. Why?\n",
    "test_size=0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)  # Split into train and test sets\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d1cca",
   "metadata": {},
   "source": [
    "# Random seed and Reproducibility\n",
    "\n",
    "**Randomness** is the lack of definite pattern or predictability in information.\n",
    "\n",
    "- A random sequence of events, symbols or steps often has no order and does not follow an intelligible pattern or combination.\n",
    "- Individual random events are, by definition, *unpredictable* (e.g., the roll of a dice)\n",
    "- ... but if there is a known probability distribution, the frequency of outcomes over repeated trials is predictable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5605b9",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "When throwing two dice, the outcome of any roll is unpredictable, but a sum of 7 will tend to occur twice as often as 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a121cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:20.682990Z",
     "iopub.status.busy": "2024-10-08T14:37:20.682990Z",
     "iopub.status.idle": "2024-10-08T14:37:21.211572Z",
     "shell.execute_reply": "2024-10-08T14:37:21.211572Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "rolls = np.random.randint(1, 7, size=100000)  # Simulate rolling a dice 100,000 times\n",
    "rolls_two_dice = rolls + np.random.randint(1, 7, size=100000)  # Simulate rolling two dice 100,000 times and summing the results\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 2.5))\n",
    "for i, x in enumerate([rolls, rolls_two_dice]):  # Plot the distribution\n",
    "    axs[i].hist(x, bins=np.arange(1, x.max() + 2) - 0.5, edgecolor='black', rwidth=0.8)\n",
    "    axs[i].set_xticks(range(1, x.max() + 1))\n",
    "    axs[i].set_xlabel('Value')\n",
    "    axs[i].set_ylabel('Frequency')\n",
    "    axs[i].set_title(f'100000 Rolls of {i + 1} Dice')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c20cd",
   "metadata": {},
   "source": [
    "# Pseudorandom number generator\n",
    "\n",
    "**Pseudorandom number generator** (PRNG) is an algorithm for generating a sequence of numbers whose properties approximate the properties of sequences of random numbers.\n",
    "\n",
    "- The PRNG-generated sequence is not truly random, because it is completely determined by an initial value, called *seed*\n",
    "- Pseudorandom number generators are important in practice for their reproducibility.\n",
    "\n",
    "`train_test_split(..., random_state=seed)` randomly shuffles data before the split is implemented.\n",
    "\n",
    "`random_state=seed` controls the randomness of the shuffle. This is essential\n",
    "\n",
    "- *Reproducibility*: By using the same random_state, you can ensure that others can replicate your results exactly.\n",
    "- *Consistency in Model Evaluation*: When comparing different models or tuning hyperparameters, the training test cannot change.\n",
    "- *Debugging and Testing*: During the development phase, you might need to debug your code or test different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210a099",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.213570Z",
     "iopub.status.busy": "2024-10-08T14:37:21.213570Z",
     "iopub.status.idle": "2024-10-08T14:37:21.218073Z",
     "shell.execute_reply": "2024-10-08T14:37:21.218073Z"
    }
   },
   "outputs": [],
   "source": [
    "print(np.random.randint(1, 7, size=10))\n",
    "print(np.random.randint(1, 7, size=10))\n",
    "np.random.seed(42)\n",
    "print(np.random.randint(1, 7, size=10))\n",
    "np.random.seed(42)\n",
    "print(np.random.randint(1, 7, size=10))\n",
    "np.random.seed(42)\n",
    "print(np.random.randint(1, 7, size=10))\n",
    "print(np.random.randint(1, 7, size=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20822d04",
   "metadata": {},
   "source": [
    "# Why `42`?\n",
    "\n",
    "![](https://images.squarespace-cdn.com/content/v1/5e5adeb728b6773d1974b095/1590696950003-QTYPKSV7KQWJYYDRN27J/frankaffe-the-answer-to-life-is-42.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6335def3",
   "metadata": {},
   "source": [
    "# Let's train some machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11b6623",
   "metadata": {},
   "source": [
    "# Models covered in this lecture\n",
    "\n",
    "Let's see how models behave\n",
    "\n",
    "- Decision tree\n",
    "- Random forest\n",
    "- k-NN\n",
    "\n",
    "It is important to understand the model dynamics!\n",
    "\n",
    "- ... not only the final result!\n",
    "- (actually, *it is mandatory for the exam!*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ast3BD39OD5a",
   "metadata": {
    "id": "Ast3BD39OD5a"
   },
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qRGDyke9OGij",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.220086Z",
     "iopub.status.busy": "2024-10-08T14:37:21.220086Z",
     "iopub.status.idle": "2024-10-08T14:37:21.293711Z",
     "shell.execute_reply": "2024-10-08T14:37:21.293711Z"
    },
    "id": "qRGDyke9OGij",
    "outputId": "28adc7ac-dafc-4623-98c5-dda0795d6ca5"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier  # Import the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=seed)  # Instantiate and fit the model (on the training set)\n",
    "clf.fit(X_train, y_train)  # Train the model\n",
    "y_pred = clf.predict(X_test)  # Predict new values\n",
    "accuracy_score(y_test, y_pred)  # Evaluate the model (on the test set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YaUP48HyXq31",
   "metadata": {
    "id": "YaUP48HyXq31"
   },
   "source": [
    "## Plotting the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TCYt3BziRjqK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.295715Z",
     "iopub.status.busy": "2024-10-08T14:37:21.295715Z",
     "iopub.status.idle": "2024-10-08T14:37:21.399435Z",
     "shell.execute_reply": "2024-10-08T14:37:21.399435Z"
    },
    "id": "TCYt3BziRjqK",
    "outputId": "a5c6ce55-6e0d-4504-e4c8-408382791a1d"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(4, 3))\n",
    "plot_tree(clf, feature_names=df.columns, class_names=['setosa', 'versicolor', 'virginica'], filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jXhw-9IuXuSo",
   "metadata": {
    "id": "jXhw-9IuXuSo"
   },
   "source": [
    "Checking feature relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JV7m4ZKqPaJm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.401484Z",
     "iopub.status.busy": "2024-10-08T14:37:21.401484Z",
     "iopub.status.idle": "2024-10-08T14:37:21.408042Z",
     "shell.execute_reply": "2024-10-08T14:37:21.408042Z"
    },
    "id": "JV7m4ZKqPaJm",
    "outputId": "efeb6271-4cec-4fcb-b621-84f298272ad7"
   },
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': clf.feature_importances_})  # Create a DataFrame to display feature importance\n",
    "feature_importance_df = feature_importance_df.sort_values(['Importance', 'Feature'], ascending=[False, True])  # Sort the DataFrame by importance in descending order\n",
    "feature_importance_df  # Display the feature importance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09124da",
   "metadata": {},
   "source": [
    "# Feature selection: checking correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8799449",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.corr(method='pearson', numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JrWbIaQTXyIF",
   "metadata": {
    "id": "JrWbIaQTXyIF"
   },
   "source": [
    "# `petal` vs `sepal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c24686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.410040Z",
     "iopub.status.busy": "2024-10-08T14:37:21.410040Z",
     "iopub.status.idle": "2024-10-08T14:37:21.412846Z",
     "shell.execute_reply": "2024-10-08T14:37:21.412846Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "# Map target labels to class names\n",
    "class_names = {0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'}\n",
    "target_names = [class_names[i] for i in range(len(class_names))]\n",
    "\n",
    "# Get the two features with the highest importance\n",
    "def plot(df, model, features):\n",
    "  # Create a scatter plot\n",
    "  plt.figure(figsize=(3.5, 2.5))\n",
    "  for x in df[\"species\"].unique():\n",
    "      plt.scatter(df[df[\"species\"] == x][features[0]], df[df[\"species\"] == x][features[1]], edgecolors='k')\n",
    "  plt.xlabel(features[0])\n",
    "  plt.ylabel(features[1])\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8h4GlwOOPlz3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.413843Z",
     "iopub.status.busy": "2024-10-08T14:37:21.413843Z",
     "iopub.status.idle": "2024-10-08T14:37:21.476238Z",
     "shell.execute_reply": "2024-10-08T14:37:21.476238Z"
    },
    "id": "8h4GlwOOPlz3",
    "outputId": "a3ff9957-5136-4fe3-d3e0-dc7a7ddf2bfe"
   },
   "outputs": [],
   "source": [
    "plot(df, clf, feature_importance_df['Feature'].iloc[:2].tolist())  # plot the 2 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nFNaqWIOT-Rd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.478285Z",
     "iopub.status.busy": "2024-10-08T14:37:21.478285Z",
     "iopub.status.idle": "2024-10-08T14:37:21.546511Z",
     "shell.execute_reply": "2024-10-08T14:37:21.546393Z"
    },
    "id": "nFNaqWIOT-Rd",
    "outputId": "e57d7a46-c26b-4bfc-c956-f67944b26ada"
   },
   "outputs": [],
   "source": [
    "plot(df, clf, feature_importance_df['Feature'].iloc[2:].tolist())  # plot the 2 lest important features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d804adb",
   "metadata": {},
   "source": [
    "# Tuning `max_depth` \n",
    "\n",
    "What do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17d0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.548646Z",
     "iopub.status.busy": "2024-10-08T14:37:21.548140Z",
     "iopub.status.idle": "2024-10-08T14:37:21.555729Z",
     "shell.execute_reply": "2024-10-08T14:37:21.555729Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#! output: false\n",
    " \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "xlabel = \"petal_length\"\n",
    "ylabel = \"petal_width\"\n",
    "ctitle = \"IRIS\"\n",
    "legend = \"species\"\n",
    "figsize = (8,6)\n",
    "xlim=[0, 7]\n",
    "ylim=[0, 3]\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# Define the colormap (Tableau)\n",
    "my_colors=['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "tableau_cmap = ListedColormap(my_colors)\n",
    "\n",
    "def plot_boundary(clf, title, norm=False):\n",
    "    # Load Iris dataset\n",
    "    iris = load_iris()\n",
    "\n",
    "    cxlim = xlim if not norm else [-0.02, 1.02]\n",
    "    cylim = ylim if not norm else [-0.02, 1.02]\n",
    "\n",
    "    X = iris.data[:, 2:4]  # Selecting petal width and petal length columns\n",
    "    y = iris.target\n",
    "    \n",
    "    if norm:\n",
    "      scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "      X = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "    # Train a classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Create a meshgrid for plotting decision boundaries\n",
    "    x_min, x_max = [cxlim[0] - 0.5, cxlim[1] + 0.5] # X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = [cylim[0] - 0.5, cylim[1] + 0.5] # X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.005), np.arange(y_min, y_max, 0.005))\n",
    "\n",
    "    # Predict the class for each point in the meshgrid\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the decision boundaries\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.contour(xx, yy, Z, colors='white', linewidths=1, alpha=0.8)\n",
    "    plt.contourf(xx, yy, Z, cmap=tableau_cmap, alpha=0.3)\n",
    "\n",
    "    # Plot the dataset points\n",
    "    for i, class_name in enumerate(target_names):\n",
    "        class_data = X_train[y_train == i]\n",
    "        plt.scatter(class_data[:, 0], class_data[:, 1], label=class_name, marker='o', color=my_colors[i], edgecolor='k', s=70)\n",
    "        class_data = X_test[y_test == i]\n",
    "        plt.scatter(class_data[:, 0], class_data[:, 1], label=class_name + \" (test)\", marker='^', color=my_colors[i], edgecolor='k', s=70)\n",
    "\n",
    "    legend_elements = [\n",
    "                      # Line2D([0], [0], marker='s', color='w', label=' ', markerfacecolor='w', markeredgecolor='w', markersize=10),\n",
    "                      Line2D([0], [0], marker=None, color='w', label=legend, markerfacecolor='w', markeredgecolor='w', markersize=10),\n",
    "                      Line2D([0], [0], marker='o',  color='w', label='Setosa', markerfacecolor='tab:blue', markeredgecolor='w', markersize=10),\n",
    "                      Line2D([0], [0], marker='o',  color='w', label='Versicolor', markerfacecolor='tab:orange', markeredgecolor='w', markersize=10),\n",
    "                      Line2D([0], [0], marker='o',  color='w', label='Virginica', markerfacecolor='tab:green', markeredgecolor='w', markersize=10),\n",
    "                      \n",
    "                      Line2D([0], [0], marker=None, color='w', label='Set',      markerfacecolor=None,     markeredgecolor='w', markersize=10),\n",
    "                      Line2D([0], [0], marker='o',  color='w', label='Training', markerfacecolor='white',  markeredgecolor='black', markersize=10),\n",
    "                      Line2D([0], [0], marker='^',  color='w', label='Test',     markerfacecolor='white',  markeredgecolor='black', markersize=10),\n",
    "                ]\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc=2, ncol=2)\n",
    "\n",
    "    plt.xlim(cxlim)\n",
    "    plt.ylim(cylim)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(ctitle)\n",
    "    # plt.legend(title=legend, loc=2)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd152e0b",
   "metadata": {},
   "source": [
    "# Decision boundaries: `max_depth=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d66e1c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.558010Z",
     "iopub.status.busy": "2024-10-08T14:37:21.557495Z",
     "iopub.status.idle": "2024-10-08T14:37:21.925338Z",
     "shell.execute_reply": "2024-10-08T14:37:21.925338Z"
    }
   },
   "outputs": [],
   "source": [
    "tree = plot_boundary(DecisionTreeClassifier(max_depth=1, random_state=seed), \"decisiontree_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcbc7e",
   "metadata": {},
   "source": [
    "# Decision boundaries: `max_depth=2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334f69e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:21.927345Z",
     "iopub.status.busy": "2024-10-08T14:37:21.927345Z",
     "iopub.status.idle": "2024-10-08T14:37:22.353823Z",
     "shell.execute_reply": "2024-10-08T14:37:22.353823Z"
    }
   },
   "outputs": [],
   "source": [
    "tree = plot_boundary(DecisionTreeClassifier(max_depth=2, random_state=seed), \"decisiontree_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088526e",
   "metadata": {},
   "source": [
    "# Decision boundaries: `max_depth=2` (changing the random seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648564ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:22.356395Z",
     "iopub.status.busy": "2024-10-08T14:37:22.355388Z",
     "iopub.status.idle": "2024-10-08T14:37:22.735730Z",
     "shell.execute_reply": "2024-10-08T14:37:22.735730Z"
    }
   },
   "outputs": [],
   "source": [
    "tree = plot_boundary(DecisionTreeClassifier(max_depth=2, random_state=1), \"decisiontree_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe59318",
   "metadata": {},
   "source": [
    "# Decision boundaries: `max_depth=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11077234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:22.737792Z",
     "iopub.status.busy": "2024-10-08T14:37:22.737792Z",
     "iopub.status.idle": "2024-10-08T14:37:23.108623Z",
     "shell.execute_reply": "2024-10-08T14:37:23.108623Z"
    }
   },
   "outputs": [],
   "source": [
    "tree = plot_boundary(DecisionTreeClassifier(max_depth=3, random_state=seed), \"decisiontree_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c7e58d",
   "metadata": {},
   "source": [
    "# Decision boundaries: `max_depth=6`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5a7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:23.110623Z",
     "iopub.status.busy": "2024-10-08T14:37:23.110623Z",
     "iopub.status.idle": "2024-10-08T14:37:23.477543Z",
     "shell.execute_reply": "2024-10-08T14:37:23.477543Z"
    }
   },
   "outputs": [],
   "source": [
    "tree = plot_boundary(DecisionTreeClassifier(max_depth=6, random_state=seed), \"decisiontree_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ba338",
   "metadata": {},
   "source": [
    "# Plotting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec6d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:23.479542Z",
     "iopub.status.busy": "2024-10-08T14:37:23.479542Z",
     "iopub.status.idle": "2024-10-08T14:37:23.591587Z",
     "shell.execute_reply": "2024-10-08T14:37:23.591587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare to store max_depth values and corresponding accuracies\n",
    "max_depths = range(1, 10)\n",
    "train_accuracies, test_accuracies = [], []\n",
    "for max_depth in max_depths:  # Train decision trees with increasing max_depth\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))  # Compute accuracy for training set\n",
    "    test_acc = accuracy_score(y_test, clf.predict(X_test))  # Compute accuracy for test set\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "# Plot accuracies\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(max_depths, train_accuracies, label=\"Training\", marker='o')\n",
    "plt.plot(max_depths, test_accuracies, label=\"Test\", marker='o')\n",
    "plt.xticks(max_depths)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0877e",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization\n",
    "\n",
    "**Hyper-parameters** are parameters that are not directly learnt within estimators.\n",
    "\n",
    "- In scikit-learn they are passed as arguments to the constructor of the estimator classes\n",
    "- How do we tune hyperparameters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fbff11",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization\n",
    "\n",
    "Hyper-parameters: parameters that are not directly learnt within estimators\n",
    "\n",
    "- In scikit-learn they are passed as arguments to the constructor of the estimator classes\n",
    "- Any parameter provided when constructing an estimator may be optimized\n",
    "\n",
    "```python\n",
    "estimator.get_params()\n",
    "```\n",
    "\n",
    "A search consists of:\n",
    "\n",
    "- an estimator $(\\checkmark)$\n",
    "- a score function $(\\checkmark)$\n",
    "- a parameter space\n",
    "- a method for searching or sampling candidates\n",
    "- a cross-validation scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166179e",
   "metadata": {},
   "source": [
    "# Parameter space (or search space)\n",
    "\n",
    "**Search Space**: space where each dimension represents a hyperparameter and each point represents one model configuration.\n",
    "\n",
    "Consider the following hyperparameters of a random forest:\n",
    "\n",
    "- `max_depth`: maximum depth of a single tre\n",
    "- `#estimators`: number of trees in the forest\n",
    "\n",
    "Assume that the domain of the two parameters is the following:\n",
    "\n",
    "- `max_depth` $\\in [1, 10]$\n",
    "- `#estimators` $\\in [2, 20]$\n",
    "\n",
    "Then, our 2D-search space is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d501a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:23.593595Z",
     "iopub.status.busy": "2024-10-08T14:37:23.593595Z",
     "iopub.status.idle": "2024-10-08T14:37:23.678208Z",
     "shell.execute_reply": "2024-10-08T14:37:23.678208Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "# Creating a hypothetical 2D dataset of max_depth and min_samples_split\n",
    "max_depth_range = np.linspace(1, 10, 10)  # 10 values for max_depth\n",
    "min_samples_split_range = np.linspace(2, 20, 10)  # 10 values for min_samples_split\n",
    "# Generate grid points for grid search\n",
    "grid_max_depth, grid_min_split = np.meshgrid(max_depth_range, min_samples_split_range)\n",
    "grid_points = np.c_[grid_max_depth.ravel(), grid_min_split.ravel()]\n",
    "# Plotting the grid search and random search scatter plots\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Scatter plot for grid search\n",
    "ax1.scatter(grid_points[:, 0], grid_points[:, 1], color='white', label='Grid Search Points')\n",
    "ax1.set_title('Search space')\n",
    "ax1.set_xlabel('max_depth')\n",
    "ax1.set_ylabel('#estimators')\n",
    "ax1.grid(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f532d6",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "\n",
    "There are many search algorithms:\n",
    "\n",
    "- *Grid search* exhaustively tries every combination of the provided hyper-parameter values in order to find the best model.\n",
    "- (Pure) *Random search* samples from the entirety of the search space\n",
    "    - It does not require to optimize a gradient, hence it can be used on functions that are not continuous or differentiable.\n",
    "    - Such optimization methods are also known as direct-search, derivative-free, or black-box methods. \n",
    "    \n",
    "    > If good parts of the search space occupy 5% of the volume the chances of hitting a good configuration is 5%.\n",
    "    >\n",
    "    > The probability of finding at least one good configuration is above 95% after trying out 60 configurations ($1 â 0.95^{60} = 0.953 > 0.95$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13c5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:23.680217Z",
     "iopub.status.busy": "2024-10-08T14:37:23.680217Z",
     "iopub.status.idle": "2024-10-08T14:37:23.842974Z",
     "shell.execute_reply": "2024-10-08T14:37:23.842974Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "# Creating a hypothetical 2D dataset of max_depth and min_samples_split\n",
    "max_depth_range = np.linspace(1, 10, 10)  # 10 values for max_depth\n",
    "min_samples_split_range = np.linspace(2, 20, 10)  # 10 values for min_samples_split\n",
    "\n",
    "# Generate grid points for grid search\n",
    "grid_max_depth, grid_min_split = np.meshgrid(max_depth_range, min_samples_split_range)\n",
    "grid_points = np.c_[grid_max_depth.ravel(), grid_min_split.ravel()]\n",
    "\n",
    "np.random.seed(seed)\n",
    "# Randomly sample points for random search\n",
    "random_points = np.array([np.random.choice(max_depth_range, 10), np.random.choice(min_samples_split_range, 10)]).T\n",
    "\n",
    "# Plotting the grid search and random search scatter plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3), sharex=True, sharey=True)\n",
    "\n",
    "# Scatter plot for grid search\n",
    "ax1.scatter(grid_points[:, 0], grid_points[:, 1], color='blue', label='Grid Search Points')\n",
    "ax1.set_title('Grid Search')\n",
    "ax1.set_xlabel('max_depth')\n",
    "ax1.set_ylabel('#estimators')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Scatter plot for random search\n",
    "ax2.scatter(random_points[:, 0], random_points[:, 1], color='green', label='Random Search Points')\n",
    "ax2.set_title('Random Search')\n",
    "ax2.set_xlabel('max_depth')\n",
    "ax2.set_yticks(list(range(2, 22, 2)))\n",
    "ax2.set_xticks(list(range(1, 11)))\n",
    "ax2.grid(True)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2282446",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "\n",
    "How do we test the hyperparameter configurations?\n",
    "\n",
    ":::: {.columns}\n",
    "::: {.column width=50%}\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n",
    "\n",
    ":::\n",
    "::: {.column width=50%}\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
    "\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe0641",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "Example of cross correlation\n",
    "\n",
    "![](https://user-images.githubusercontent.com/18005592/232802005-d3a1aff6-23d8-4704-8a3f-a219d2155d30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e21083",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c6cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:23.844972Z",
     "iopub.status.busy": "2024-10-08T14:37:23.844972Z",
     "iopub.status.idle": "2024-10-08T14:37:31.745548Z",
     "shell.execute_reply": "2024-10-08T14:37:31.745548Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "rf = RandomForestClassifier(random_state=seed)  # Define a Random Forest Classifier\n",
    "param_dist = {  # Set up the parameter grid for random search\n",
    "    'n_estimators': randint(2, 200),        # Number of trees in the forest\n",
    "    'max_depth': randint(2, 20),            # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 20),    # Minimum number of samples to split a node\n",
    "    'min_samples_leaf': randint(1, 20),     # Minimum number of samples in a leaf node\n",
    "}\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=50, scoring='accuracy', cv=5, random_state=seed, n_jobs=-1)  # Setup RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)  # Fit the random search model\n",
    "print(\"Best Parameters from Random Search:\", random_search.best_params_)  # Output the best parameters \n",
    "best_rf = random_search.best_estimator_\n",
    "test_accuracy = best_rf.score(X_test, y_test)  # Evaluate the model with the best parameters on the test set\n",
    "print(\"Best Cross-validation Accuracy:\", random_search.best_score_, \"Test Set Accuracy with Best Parameters:\", test_accuracy)  # Output the best score\n",
    "forest = plot_boundary(best_rf, \"rf_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0805ff",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e55d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:31.747548Z",
     "iopub.status.busy": "2024-10-08T14:37:31.747548Z",
     "iopub.status.idle": "2024-10-08T14:37:31.882992Z",
     "shell.execute_reply": "2024-10-08T14:37:31.882992Z"
    }
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "X = iris.data[:, 2:4]  # Selecting petal width and petal length columns\n",
    "y = iris.target\n",
    "# Plot the dataset points\n",
    "for i, class_name in enumerate(target_names):\n",
    "    class_data = X[y == i]\n",
    "    plt.scatter(class_data[:, 0], class_data[:, 1], label=class_name, edgecolor='k', s=70)\n",
    "\n",
    "plt.xlim(xlim)\n",
    "plt.ylim(ylim)\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.title(ctitle)\n",
    "plt.legend(title=legend, loc=2)\n",
    "\n",
    "# for ext in [\"svg\", \"pdf\", \"jpg\"]:\n",
    "#   plt.savefig(f'iris.{ext}')\n",
    "\n",
    "plt.scatter(5, 1.3, s=5000, facecolors='none', edgecolors='black', linestyle='--')\n",
    "plt.scatter(5, 1.3, s=100, marker=\"D\", facecolors='black', edgecolors='black')\n",
    "\n",
    "# for ext in [\"svg\", \"pdf\", \"jpg\"]:\n",
    "#   plt.savefig(f'knn.{ext}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3ef9e",
   "metadata": {},
   "source": [
    "# Tuning `k` \n",
    "\n",
    "What do you expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36baf0b",
   "metadata": {},
   "source": [
    "# Decision boundaries: `k=1` (no normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f0aeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:31.884990Z",
     "iopub.status.busy": "2024-10-08T14:37:31.884990Z",
     "iopub.status.idle": "2024-10-08T14:37:57.469624Z",
     "shell.execute_reply": "2024-10-08T14:37:57.469624Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = plot_boundary(KNeighborsClassifier(n_neighbors=1), \"knn_cplot\", norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce3b793",
   "metadata": {},
   "source": [
    "# Decision boundaries: `k=1` (min-max normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b352a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:37:57.471628Z",
     "iopub.status.busy": "2024-10-08T14:37:57.471628Z",
     "iopub.status.idle": "2024-10-08T14:38:00.955325Z",
     "shell.execute_reply": "2024-10-08T14:38:00.955325Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = plot_boundary(KNeighborsClassifier(n_neighbors=1), \"knn_cplot\", norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3bcf9",
   "metadata": {},
   "source": [
    "# Decision boundaries: `k=10` (min-max normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2f5371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:38:00.957367Z",
     "iopub.status.busy": "2024-10-08T14:38:00.957367Z",
     "iopub.status.idle": "2024-10-08T14:38:04.581936Z",
     "shell.execute_reply": "2024-10-08T14:38:04.581936Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = plot_boundary(KNeighborsClassifier(n_neighbors=10), \"knn_cplot\", norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ee2b9",
   "metadata": {},
   "source": [
    "# Plotting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f79431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:38:04.583941Z",
     "iopub.status.busy": "2024-10-08T14:38:04.583941Z",
     "iopub.status.idle": "2024-10-08T14:38:04.683952Z",
     "shell.execute_reply": "2024-10-08T14:38:04.683952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare to store max_depth values and corresponding accuracies\n",
    "k_s = range(1, 10)\n",
    "train_accuracies, test_accuracies = [], []\n",
    "for k in k_s:  # Train decision trees with increasing max_depth\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))  # Compute accuracy for training set\n",
    "    test_acc = accuracy_score(y_test, clf.predict(X_test))  # Compute accuracy for test set\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "# Plot accuracies\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(max_depths, train_accuracies, label=\"Training\", marker='o')\n",
    "plt.plot(max_depths, test_accuracies, label=\"Test\", marker='o')\n",
    "plt.xticks(max_depths)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c452c1",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "Perceptron is binary classifier.\n",
    "How can we use it in Iris? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e062505",
   "metadata": {},
   "source": [
    "# One Versus All\n",
    "\n",
    ":::: {.columns}\n",
    "::: {.column width=\"60%\"}\n",
    "\n",
    "One Versus All (OVA) strategy for multiclasses\n",
    "\n",
    "- OVA provides a way to use binary classification for a series of yes or no predictions across multiple possible labels.\n",
    "- Given a classification problem with N possible solutions, a OVA solution consists of N separate binary classifiersâone binary classifier for each possible outcome.\n",
    "- During training, the model runs through a sequence of binary classifiers, training each to answer a separate classification question.\n",
    "- Finally, pick the prediction of a non -zero class which is the most certain and use argmax of these score(class index with largest score) is then used to predict a class.\n",
    "\n",
    ":::\n",
    "::: {.column width=\"40%\"}\n",
    "\n",
    "For example, given a picture of a piece of fruit, four different recognizers might be trained, each answering a different yes/no question:\n",
    "\n",
    "    Is this image an apple?\n",
    "    Is this image an orange?\n",
    "    Is this image a banana?\n",
    "    Is this image a grape?\n",
    "\n",
    "![](https://developers.google.com/static/machine-learning/crash-course/neural-networks/images/one_vs_all_binary_classifiers.png)\n",
    "\n",
    ":::\n",
    "::::\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9843713e",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9e754",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:38:04.685993Z",
     "iopub.status.busy": "2024-10-08T14:38:04.685993Z",
     "iopub.status.idle": "2024-10-08T14:38:05.064982Z",
     "shell.execute_reply": "2024-10-08T14:38:05.064982Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = plot_boundary(Perceptron(random_state=seed), \"perceptron_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f3a5c",
   "metadata": {},
   "source": [
    "# Perceptron: changing the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0a645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:38:05.067024Z",
     "iopub.status.busy": "2024-10-08T14:38:05.067024Z",
     "iopub.status.idle": "2024-10-08T14:38:05.443708Z",
     "shell.execute_reply": "2024-10-08T14:38:05.443664Z"
    }
   },
   "outputs": [],
   "source": [
    "perceptron = plot_boundary(Perceptron(random_state=1), \"perceptron_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded4e4b",
   "metadata": {},
   "source": [
    "# Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b111d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T14:38:05.445831Z",
     "iopub.status.busy": "2024-10-08T14:38:05.445328Z",
     "iopub.status.idle": "2024-10-08T14:38:06.242748Z",
     "shell.execute_reply": "2024-10-08T14:38:06.242748Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = plot_boundary(MLPClassifier(hidden_layer_sizes=(10, 20), random_state=seed, max_iter=1000), \"mlp_cplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e552378",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "1. Load the `wine` dataset from `sklearn`\n",
    "1. Train a decision tree\n",
    "1. ... try different configurations of hyperparameters\n",
    "1. What is your best accuracy?\n",
    "1. What are the most relevant features?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
